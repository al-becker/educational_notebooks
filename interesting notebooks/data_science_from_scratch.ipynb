{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Linear Algebra\n",
    "\n",
    "## Vectors\n",
    "Vector is a geometric object that has magnitude (or length) and direction. Vectors can be added to other vectors according to vector algebra. Concretely, vectors are points in some finite-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Callable, TypeVar, Iterator, NamedTuple, Set, Iterable\n",
    "\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "height_weight_age = [70,  # inches,\n",
    "                     170, # pounds,\n",
    "                     40]  # years\n",
    "\n",
    "grades = [95, # exam1\n",
    "          80, # exam2\n",
    "          75, # exam3\n",
    "          62] # exam4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[5, 7, 9]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "def add(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"Adds corresponding elements\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be the same length\"\n",
    "    \n",
    "    return [v_i + w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "\n",
    "add([1,2,3],[4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[-3, -3, -3]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "def subtract(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"Subtracts corresponding elements\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be the same length\"\n",
    "    \n",
    "    return [v_i - w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "\n",
    "subtract([1,2,3],[4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[16, 20]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "def vector_sum(vectors: List[Vector]) -> Vector:\n",
    "    \"\"\"Sums all corresponding elements\"\"\"\n",
    "    assert vectors, \"no vectors provided!\"\n",
    "    \n",
    "    num_elements = len(vectors[0])\n",
    "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
    "    \n",
    "    return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\n",
    "\n",
    "\n",
    "vector_sum([[1,2],[3,4],[5,6],[7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 4, 6]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "def scalar_multiply(c: float, v: Vector) -> Vector:\n",
    "    \"\"\"Multiplies every element by c\"\"\"\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "\n",
    "scalar_multiply(2,[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[3.0, 4.0]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "def vector_mean(vectors: List[Vector]) -> Vector:\n",
    "    \"\"\"Computes the element-wise average\"\"\"\n",
    "    n = len(vectors)\n",
    "    return scalar_multiply(1/n, vector_sum(vectors))\n",
    "\n",
    "\n",
    "vector_mean([[1,2],[3,4],[5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "def dot(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w), \"vectos must be same length\"\n",
    "    \n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v,w))\n",
    "\n",
    "\n",
    "dot([1, 2, 3], [4, 5, 6]) # 1*4 + 2*5 + 3*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If w has magnitude 1, the dot product measures how far the vector v extends in the w direction. For example, if w = [1, 0], then dot(v,w) is just the first component of v. Another way of saying this is that it's the length of the vector you'd get if you projected v onto w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "14"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "def sum_of_squares(v: Vector) -> float:\n",
    "    \"\"\"Returns v_1 * v_1 + ... + v_n + v_n\"\"\"\n",
    "    return dot(v,v)\n",
    "\n",
    "\n",
    "sum_of_squares([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def magnitude(v: Vector) -> float:\n",
    "    \"\"\"Returns the magnitude (or length) of v\"\"\"\n",
    "    return math.sqrt(sum_of_squares(v)) # math.sqrt is square root funtion\n",
    "\n",
    "\n",
    "magnitude([3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the distance between two vectors: $$\\sqrt{(v_1 - w_1)^2 + ... + (v_n - w_n)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "10.0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "def squared_distance(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"Computes (v_1 - w_1) ** 2 + ... + (v_n - w_n) ** 2\"\"\"\n",
    "    return sum_of_squares(subtract(v,w))\n",
    "\n",
    "def distance(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"Computes the distance between v and w\"\"\"\n",
    "    return math.sqrt(squared_distance(v,w))\n",
    "\n",
    "#alternative\n",
    "def distance(v: Vector, w: Vector) -> Vector:\n",
    "    return magnitude(subtract(v,w))\n",
    "\n",
    "distance([3,4],[9,12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Matrix = List[List[float]]\n",
    "\n",
    "A = [[1,2,3],\n",
    "     [4,5,6]]\n",
    "\n",
    "B = [[1,2],\n",
    "     [3,4],\n",
    "     [5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 3)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "def shape(A: Matrix) -> Tuple[int,int]:\n",
    "    \"\"\"Returns (# of rows of A, # of columns of A)\"\"\"\n",
    "    num_rows = len(A)\n",
    "    num_columns = len(A[0]) if A else 0\n",
    "    return num_rows, num_columns\n",
    "\n",
    "shape(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[1, 0, 0, 0, 0],\n [0, 1, 0, 0, 0],\n [0, 0, 1, 0, 0],\n [0, 0, 0, 1, 0],\n [0, 0, 0, 0, 1]]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "def get_row(A: Matrix, i: int) -> Vector:\n",
    "    \"\"\"Returns the i-th row of A (as a Vector)\"\"\"\n",
    "    return A[i]\n",
    "\n",
    "def get_column(A: Matrix, j: int) -> Vector:\n",
    "    \"\"\"Returns the j-th column of A (as a Vector)\"\"\"\n",
    "    return [A_i[j] for A_i in A]\n",
    "\n",
    "def make_matrix(num_rows: int,\n",
    "                num_cols: int,\n",
    "                entry_fn: Callable[[int, int], float]) -> Matrix:\n",
    "    \"\"\"Returns a num_rows x num_cols matrix whose (i,j)-th entry is entry_fn(i,j)\"\"\"\n",
    "    return [[entry_fn(i,j) for j in range(num_cols)] for i in range(num_rows)]\n",
    "\n",
    "def identity_matrix(n: int) -> Matrix:\n",
    "    \"\"\"Returns the n x n identity matrix\"\"\"\n",
    "    return make_matrix(n,n, lambda i, j: 1 if i==j else 0)\n",
    "\n",
    "identity_matrix(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mean(xs: Vector) -> float:\n",
    "    return sum(xs) / len(xs)\n",
    "\n",
    "def de_mean(xs: Vector) -> Vector:\n",
    "    \"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = mean(xs)\n",
    "    return [x - x_bar for x in xs]\n",
    "\n",
    "def variance(xs: Vector) -> float:\n",
    "    \"\"\"Almost the average squared deviation from the mean\"\"\"\n",
    "    assert len(xs) >= 2, \"variance requires at least two elements\"\n",
    "\n",
    "    n = len(xs)\n",
    "    deviations = de_mean(xs)\n",
    "    return sum_of_squares(deviations) / (n - 1)\n",
    "\n",
    "def standard_deviation(xs: Vector) -> float:\n",
    "    \"\"\"The standard deviation is the square root of the variance\"\"\"\n",
    "    return math.sqrt(variance(xs))\n",
    "\n",
    "def covariance(xs: Vector, ys: Vector) -> float:\n",
    "    assert len(xs) == len(ys), \"xs and ys must have same number of elements\"\n",
    "\n",
    "    return dot(de_mean(xs), de_mean(ys)) / (len(xs) - 1)\n",
    "\n",
    "def correlation(xs: Vector, ys: Vector) -> float:\n",
    "    \"\"\"Measures how much xs and ys vary in tandem about their means\"\"\"\n",
    "    stdev_x = standard_deviation(xs)\n",
    "    stdev_y = standard_deviation(ys)\n",
    "    if stdev_x > 0 and stdev_y > 0:\n",
    "        return covariance(xs, ys) / stdev_x / stdev_y\n",
    "    else:\n",
    "        return 0    # if no variation, correlation is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we frequently will need to maximize or minimize functions that take as input a vector of real numbers and output a single real number. For functions like this, the gradient (if you remember your calculus, this is the vector of partial derivatives) gives the direction in which the function most quickly increases. Accordingly, one approach to maximize a function is to take a pick a random starting point, compute the gradient, take a small step in the direction of the gradient (i.e., the direction that causes the function to increase the most), and repeat with the new starting point. Similarly, you can try to minimize a function by taking small steps in the opposite direction.\n",
    "\n",
    "If a function has a unique global minimum, this procedure is likely to find it. If a function has multiple (local) minima, this procedure might \"find\" the wrong one of them, in which case you might rerun the procedure from different starting points. If a function has no minimum, then it's possible the procedure might go on forever.\n",
    "\n",
    "Wikipedia: In numerical mathematics, numerical differentiation is the approximate calculation of the derivative from given function values, usually by means of a difference quotient. This is necessary if the derivative function is not given or the function itself is only available indirectly, for example via measured values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def difference_quotient(f: Callable[[float], float],\n",
    "                        x: float,\n",
    "                        h: float) -> float:\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When f is a function of many variables, it has multiple partial derivatives, each indicating how f changes when we make small changes in just one of the input variables. We calculate its ith partial derivative by treating it as a function of just its ith variable, holding the other variables fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def partial_difference_quotient(f: Callable[[Vector], float],\n",
    "                                v: Vector,\n",
    "                                i: int,\n",
    "                                h: float) -> float:\n",
    "    \"\"\"Returns the i-th partial difference quotient of f at v\"\"\"\n",
    "    w = [v_j + (h if j == i else 0) for j, v_j in enumerate(v)]\n",
    "    return (f(w) - f(v)) / h\n",
    "\n",
    "def estimate_gradient(f: Callable[[Vector], float],\n",
    "                      v: Vector,\n",
    "                      h: float = 0.0001):\n",
    "    return [partial_difference_quotient(f, v, i, h) for i in range(len(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Gradient\n",
    "\n",
    "To compute the minimum for the sum_of_squares function (obviously it is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
    "    \"\"\"Moves 'step_size' in the 'gradient' direction from 'v'\"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)\n",
    "\n",
    "# to compute the gradient directly\n",
    "def sum_of_squares_gradient(v: Vector) -> Vector:\n",
    "    return [2 * v_i for v_i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 [7.064115430982113, -2.753611344339859, 2.8159964724515074]\n100 [0.9367964822238486, -0.3652260826153464, 0.3734128325554842]\n200 [0.12419416441412795, -0.048479489899833916, 0.04947847499671268]\n300 [0.01642720590711574, -0.006472697442725336, 0.006518444358208493]\n400 [0.0021351997297880997, -0.000901775282500602, 0.0008211041737050065]\n500 [0.0002398002177058323, -0.00016296205968735784, 6.552544865482375e-05]\n600 [-1.1566823829649716e-05, -6.498097818869402e-05, -3.467906630485518e-05]\n700 [-4.4903009244663344e-05, -5.198677067425358e-05, -4.796814457745694e-05]\n800 [-4.9324039349627585e-05, -5.026348464448423e-05, -4.9730536236219985e-05]\n900 [-4.991035439874528e-05, -5.0034943216536596e-05, -4.996426383531776e-05]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# pick a random starting point\n",
    "v = [random.uniform(-10, 10) for i in range(3)]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    grad = estimate_gradient(sum_of_squares, v)\n",
    "    v = gradient_step(v, grad, -0.01)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a certain point we stop improving our prediction. The further increase the prediction we can either reduce the stepsize or reduce h since we can no longer optimaly predict the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gradient Descent to Fit Models\n",
    "\n",
    "Example: In this case we know the parameters of the linear relationship between x and y, but imagine we'd like to learn them from the data. We'll use gradient descent to find the slope and intercept that minimize the average squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 [32.865541242711124, -0.05083563541509259]\n200 [19.99797024183235, 1.6204514317879215]\n400 [19.998639793558638, 2.7352554581886697]\n600 [19.99908848177452, 3.482321607119942]\n800 [19.99938916222559, 3.9829547387394117]\n1000 [19.999590657897762, 4.318445153923746]\n1200 [19.999725686649246, 4.543268106245071]\n1400 [19.999816173772526, 4.693929220848609]\n1600 [19.999876812113538, 4.794892095053462]\n1800 [19.999917447822437, 4.86255057477816]\n2000 [19.999944679122144, 4.907890705144991]\n2200",
      " [19.99996292769474, 4.938274589471774]\n2400",
      " [19.99997515665205, 4.958635810741188]\n2600 [19.999983351670927, 4.972280522099463]\n2800 [19.99998884341751, 4.981424283447915]\n3000 [19.99999252361409, 4.98755181296482]\n3200 [19.99999498983256, 4.991658068208115]\n3400 [19.99999664252514, 4.994409802341198]\n3600 [19.99999775004776, 4.996253828172644]\n3800 [19.999998492234408, 4.997489569382577]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "[19.99999898757338, 4.998314309070989]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "# ranges from - 50 to 49, y is always 20 * x + 5\n",
    "inputs = [(x, 20 * x + 5) for x in range(-50, 50)]\n",
    "\n",
    "def linear_gradient(x: float, y: float, theta: Vector) -> Vector:\n",
    "    slope, intercept = theta\n",
    "    predicted = slope * x + intercept\n",
    "    error = (predicted - y)\n",
    "    squared_error = error ** 2\n",
    "    grad = [2 * error * x, 2 * error]\n",
    "    return grad\n",
    "\n",
    "# random values for slope and intercept\n",
    "theta = [random.uniform(-1,1), random.uniform(-1,1)]\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(4000):\n",
    "    grad = vector_mean([linear_gradient(x,y,theta) for x,y in inputs])\n",
    "    theta = gradient_step(theta,grad,-learning_rate)\n",
    "    if epoch % 200 == 0:\n",
    "        print(epoch, theta)\n",
    "        \n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatch and Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "def minibatches(dataset: List[T],\n",
    "                batch_size: int,\n",
    "                shuffle: bool = True) -> Iterator[List[T]]:\n",
    "    \"\"\"Generates 'batch_size'-sized minibatches from the dataset\"\"\"\n",
    "    batch_starts = [start for start in range(0,len(dataset),batch_size)]\n",
    "    \n",
    "    if shuffle: random.shuffle(batch_starts)\n",
    "        \n",
    "    for start in batch_starts:\n",
    "        end = start + batch_size\n",
    "        yield dataset[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 [18.685337066135055, 1.3280137843182587]\n100",
      " [19.718890963177525, 3.8637600672453285]\n200 [19.93274004969401, 4.724512376854973]\n300 [19.99176498148756, 4.949289002667753]\n400 [19.999519059197674, 4.9854607496002314]\n500 [19.999821302558686, 4.996616611138997]\n600 [20.00010984623067, 4.999366377437945]\n700 [20.00003897381826, 4.999766977068455]\n800 [19.99999944559982, 4.9999236109196525]\n900 [20.000003870474504, 4.999979644033054]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "[19.999999650228204, 4.99999342096177]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for batch in minibatches(inputs, batch_size=20):\n",
    "        grad = vector_mean([linear_gradient(x, y, theta) for x, y in batch])\n",
    "        theta = gradient_step(theta, grad, -learning_rate)\n",
    "    if epoch%100 == 0: print(epoch, theta)\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 [20.105950611028383, -0.2733841109083178]\n10 [20.068337128482014, 1.5986956640707362]\n20 [20.04407706760384, 2.806177024422845]\n30 [20.028429471719686, 3.5849959969687477]\n40 [20.018336858275607, 4.087330040350964]\n50 [20.01182717768274, 4.411332792337129]\n60 [20.007628466977994, 4.6203128220461425]\n70 [20.00492030933308, 4.755103815975301]\n80 [20.003173584895897, 4.842043279373795]\n90 [20.002046942599446, 4.898118766833173]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x, y in inputs:\n",
    "        grad = linear_gradient(x, y, theta)\n",
    "        theta = gradient_step(theta, grad, -learning_rate)\n",
    "    if epoch%10 == 0: print(epoch, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "Nearest neighbors is one of the simplest predictive models there is. The only things it requires are:\n",
    "- some notion of distance\n",
    "- an assumption that points that are close to one another are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def majority_vote(labels: List[str]) -> str:\n",
    "    \"\"\"Assumes that labels are ordered from nearest to farthest.\"\"\"\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count\n",
    "                       for count in vote_counts.values()\n",
    "                       if count == winner_count])\n",
    "\n",
    "    if num_winners == 1:\n",
    "        return winner                     # unique winner, so return it\n",
    "    else:\n",
    "        return majority_vote(labels[:-1]) # try again without the farthest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class LabeledPoint(NamedTuple):\n",
    "    point: Vector\n",
    "    label: str\n",
    "\n",
    "def knn_classify(k: int,\n",
    "                 labeled_points: List[LabeledPoint],\n",
    "                 new_point: Vector) -> str:\n",
    "\n",
    "    # Order the labeled points from nearest to farthe st.\n",
    "    by_distance = sorted(labeled_points,\n",
    "                         key=lambda lp: distance(lp.point, new_point))\n",
    "\n",
    "    # Find the labels for the k closest\n",
    "    k_nearest_labels = [lp.label for lp in by_distance[:k]]\n",
    "\n",
    "    # and let them vote.\n",
    "    return majority_vote(k_nearest_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Iris Dataset\n",
    "\n",
    "contains a bunch of measurements for 150 flowers representing three species of iris. For each flower we have its petal length, petal width, sepal length, and sepal width, as well as its species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get(\n",
    "  \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    ")\n",
    "\n",
    "with open('iris.dat', 'w') as f:\n",
    "    f.write(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "represent iris data as LabeldPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_iris_row(row: List[str]) -> LabeledPoint:\n",
    "    \"\"\"sepal_length, sepal_width, petal_length, petal_width, class\"\"\"\n",
    "    measurements = [float(value) for value in row[:-1]]\n",
    "    label = row[-1].split('-')[-1]\n",
    "    \n",
    "    return LabeledPoint(measurements, label)\n",
    "\n",
    "with open('iris.dat') as f:\n",
    "    reader = csv.reader(f)\n",
    "    # if row helps to ignore empty rows\n",
    "    iris_data = [parse_iris_row(row) for row in reader if row]\n",
    "    \n",
    "# group just the points by species/label so we can plot them\n",
    "points_by_species: Dict[str, List[Vector]] = defaultdict(list)\n",
    "for iris in iris_data:\n",
    "    points_by_species[iris.label].append(iris.point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x720 with 6 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAI+CAYAAADzSlRVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAACCG0lEQVR4nO3df5gddX33/9fnbLJJaxbYVMttITZQv3WDJYm6BNNKTSgKlhRKKy6VBZPe97eU8O2lF5aot/222NYKG6n2R5Yb77uCsGld0cuCoQaLJJoqEjaygZZdvG8ETbD+arZk99smm5zz+f4xZ07OmT0zZ86cmTMz5zwf15VrM2fmzHzm7J73zHs+v4y1VgAAAAAA+CmkXQAAAAAAQLaROAIAAAAAApE4AgAAAAACkTgCAAAAAAKROAIAAAAAApE4AgAAAAACkTjmhDHmn3xe32uMWdTivtcaY15f/v8GY8yftrK/JBhjVhpjxpp8z2XGmMs9r20wxtxa/v9vV71e9/MF0D6dHOfKMeziBuvrxrg44lP5nM8t/3+zMea/tbpPAK0h5nFflzckjpCktZJen3Yh4mat3W2tfShgk98OWAegs6xVunFupSTfm6g22CDp3BSPD6C91qrDYh73dekjcUyIMeYXjTGPG2P2GGP+a/m1Pyw/RXq0/KRlpTHma8aYB40x3zDGnFPe7jPGmK8YY75kjDkt5PFeUd7PHmPMaPm1W40x9xpjHjHG/K/yaz9XLtcDxpgvG2NWSvodSbcYY3aWd/cGY8wXymVbVnWMs4wxny7/v6d8LsvLP/cYY/7SU6arjDH7y+f7q8ZxZ3n5IWNMf/lJ0ZeMMV8sv77cGLO4XLavGmM+Z4zpCTjv1xpj7ij//7Ax5nXGmI3GmG3VT9WNMZ80xjwiyV3+HUnnl8t+vqRFxpj/aYyZNMZcFuYzB7odca5Se/eAMebh8s/eerGufPzryuUJHeM8x3p1+fP6ijHmD8qv3WOM+R/GmH8yxvxR+bULjTHfNMb8Xflnr6TNku5w46Wktxlj/qH8z4Q5PtDtiHnJxzzDfV2mkTgm522S3met3Sjpk8aY1ZLOstZukHSTpA+Ut1su6TckvVvS+8qvbbbWvlnSZyQNhTze+yV9pHy8WWPM+vLrT1prL5H0KmPMGZJ+v3ys35D00+VtPiFpu7X22vLyvLX21yT9g6RfcQ9grX1RUr8xZqmkiyR9VdLrJO0tH/fdnjL9hqR3WGsvlvRFSZskfbe8/NeSfre8nbHWvk3SXXICzUlJm6y1vyxpSsFPrJ6RtKocJP9F0i9K+iVJX3c3MMask1Qsfw7PlM/lE5KettZusNY+Lef38EFJl0u6IeB4AE4hzjl+aK29VE7c+Q3Vj3WfkHSftfZX1FyMq/ZhSf+1/Lm91hhzdvn1h621b5L0q+Xl/1fSFXJuqF5lrZ2XdI+k91pr31ve5rC19lclvShpdcjjA92OmOdIMuZxX5dhLbWfRqA7Jf1B+cnIX8qpst9gjNlbXv+v5Z9PW2tPGmMmJb26/BRme/lpyWmSPh/yeKsk3WaMsZKWSdpffv2fyz+/J+l0SedIespaWzTG/PPC3dS850VJZ3jWPSwncF4s6X/KCQBvLj/R2i3pvqptPyznM1hU/v8qSdcYYy6V87f3WHm7J8s/JyW9RdLLJH3CGHOWpDMl/e/yvwWstdYYc7xcnr+Wc7P0ckkflfTq8mbnVh3jgKT13v1I+pG19oeSVA7CABojzjmqY9gFkuZVP9a5Qsc4j9dIuq9cQXiGpLM85/Kf5Z+nWWsPS5Ixxm+/QecPoD5iniOxmMd9XbaROCZnxlq71RjzM5L+Rs5TqC9Za39Pkowxi+Vc9H+hHFDWSHpOTpv0l1lrf9kY83/r1I1BI89KGrPWHijvf5Gk8yXZqm2MpOflVOVPSHpt+fUTkpZUbed9T7XPSvqIpFdaa58yxiy11v5h+ZiTqg0u37HW/jdjzC9KullO8LnXWus2QVgs5ynSmvL27mdwqaRvWWvfaYz5cJ0yeB2Q9P9I2ijp7ZKWWGuPmVOtr54vr5Ocp2j1zjPonAHUR5xzeGPYf2hhrFsnyW2e1WyMcz0r6T3W2n8tf55W0o2ec5Gko+Xfyb/r1I3WiarjS8Q8IApiniPpmMd9XUaROCbnBmPMb8h5QnS7tXbSGPP98lMpK+nvJH1J0g8l/b2kV0i6VtIP5Dyd2i3pkJwnQ2H8mZynOadLKqnc5ruOj0raWT7ujJzA8g1J9xhjfkHS54IOYq39rnHa6+8tv7TOGPNnkhZLesSz+a3GmDfK+QzeK+krkv7SGPNoef3HJR2VdKJ8vksl/aakn5D0QWPMoKSX1PhJ/NckXW2tfckYc1jSjz1lftwYc6Mx5suSviPpu+VVh4wxn5PTlAFA84hzjp8yxnxJ0jFJV8t5+u6NdV+R9BFjzLiceNhMjHN9UE7zuCXlc/pNn+3+RNIXJP0fOZ+vyufyEWPMhToVAwE0h5jnSDrmcV+XUcZa74NKtEu5/fafWmuH23jMReXmEz1yvphvstaebNfx65Rng6RLrLV/kFYZACSn0+OcMWazpEXW2v+VxP6jqDr/l8mpDfmltMsEdAtiHjoZNY45Yox5t6Srql76vLX2L5rczbnGGYXrZZL+Js2kMQpjzEdU25b9TmvteFrlARCvbo9zMcW4XzLG/LGkPkl/HFvhAMSOmMd9XZ5Q4wgAAAAACMR0HAAAAACAQCSOAAAAAIBAJI4AAAAAgEBNDY7z8pe/3K5cuTKhogDIowMHDvzYWvuKtMsRJ2IdAC9iHYBu4RfvmkocV65cqYmJifhKBSD3jDHfSbsMcSPWAfAi1gHoFn7xjqaqAAAAAIBAJI4AAAAAgEAkjgAAAACAQCSOAAAAAIBAJI4AAAAAgEAkjgAAIJestYHLAOLXzu9dFr7jWShDVpA4doihux7T0F2PpV0MAADaYnRyVCNPjFRu4qy1GnliRKOToymXDOhc7fzeZeE7noUyZAmJIwAAyBVrrWbnZzU2NVa5qRt5YkRjU2OanZ/t6hoBICnt/N5l4TuehTJkzaK0C4DWuLWMjz9/pGZ5/Ib1qZUJAIAkGWO07YJtkqSxqTGNTY1JkoZXDWvbBdtkjEmzeEBHauf3Lgvf8SyUIWuocQQAALlTfVPn6tabOaBd2vm9y8J3PAtlyBISx5wbv2G9xm9YrwvPWa4Lz1leWQYAoJO5zcaqVfdFAhC/dn7vsvAdz0IZsoTEEQAA5Ep1X6PhVcN66vqnNLxquKYvEoB4tfN7l4XveBbKkDX0cewQ1DICALqFMUZ9vX01fY3c5mR9vX1d24wMSFI7v3dZ+I5noQxZY5rJlgcHB+3ExESCxQGQN8aYA9bawbTLESdiHZAPxWJRPT09vstxItYBDmttTdLkXc7rsbJchnbzi3c0VQUAALmzZfcWXfPQNSqVSpKkUqmkax66Rlt2b0m5ZEBymIy+/bxJYqcnjUFIHAEAQK6USiXNzc9pemZaQ7uGVCqVNLRrSNMz05qbn6skk0AnycJk9O0sQxbOF7VIHAEAQKZ5a1WMMRrfNK6B/gFNz0xrzX1rND0zrYH+AY1vGlehwO0NOksWJqNvZxmycL5YiMFxAABAZo1Ojmp2frYyOIV7A9nX26fxTeNac9+ayrYkjehUWZiMvp1lyML5YiGiKwAAyKSgWoeXjr2kd+x6R832brNVoBNlYTL6dpYhC+eLWiSOAAAgk9wbR3futNX3rtbY1Jje+Zp36sAPD+jZmWc10D+gg9cdrDRbJXlEp8rCZPTtLEMWzhe1SBwBAEBm1at1eP+F71dfb19Nn0a3z+Oy3mU0V0XHycJk9O0sQxbOFwvRxxEAAGSWX63DJy/9pKy1lSTRTR5JGtGJsjAZfTvLkIXzxUKmmYydiWIBeDEpNoCkeGsdtl2wbcFyu24giXXIgixMRt/OMmThfLuRX7yjxhEAAGQStQ5ArSxMRt/OMmThfHEKiSMAAMisrWu31tQyuMlj1BtIajCAcKJ8V+L+fgXtz29dqVSqabLuXc6jrJwTiWMGDd31mCRp/Ib1KZcEAID0xVXrEDQn5Na1W+MoKtARonxX4v5+Be1PUt11X/7ul3V67+mV/s6lUklDu4a0rHeZ7r7s7pY+k7Rs2b1Fc/NzmTinfKffAAAAIQTNCTk7P8sojUBZlO9K3N+voP0dnT+qo8eP1l137OSxmml5hnYNaXpmWnPzc7mcpqdUKmlufi4z58TgOBni1jQ+/vwRSdKF5yyXRM0jso0BIwDkRfUNpivsIDvEOnSTKN+VVr5fze5PUt11v/+G39c1D12j6ZnpyuvV0/bkUXWy6Er6nPziXT4/QQAAkFneh9JZqc2rNydkO0dmBfIiyncl7u9X0P781vX09Gh803jN63lOGqVTUw1VS+uc8vspdqDxG9Zr/Ib1uvCc5brwnOWVZQAA8mJ0crRmgm631mB0cjTlkvnPCZmVxBbIiijflbi/X0H781tXLBY1tGuo5nW3iWdeuTWO1dI6JxJHAAAQiyz3I/TOCfnU9U9peNVwTVkBRPuuxP39Ctrf7U/crtv331533cb7N2p6ZloD/QM6eN1BDfQP1PQPzJvqZqpZOCdGVc0gahkBAHlU3XxsbGqs0v+olX5OcZaNOSGBxqJ8V+L+fjXan6S667783S9r4CdP9f8b3zReGYE0j81VC4WClvUuq+nTmOY5MTgOgJYwYAQAL2utVt+7urL81PVPZSYxizrPHLEO3YZ5HLOj3efE4DgAACBxWe9HGNeckECni/u7EmXQrKAy+K3zJlR5Txql7MQtmqrGwJ1GgyamAIBu5u2XtO2CbTVD5qfdXBVAckYnRzU7P1v5nrvxwG1a6rdu69qtKZc824I+13Z/dvlPwQEAQNvVqz3w65c0vGq4cvMYtI84ygCg/YIGxjo6f1RHjx/N5KBZWZe1AceocWyBW9P4+PNHapapeQQAdLJGT8Cr+x65yeOdB+/UyBMjsT01z9JTeKDbNRoYy90ma4NmZV3WBhyjxhEAAIQW5gl4vZuZOJ+aZ+0pPIDaJMflJjdB6xAsS58dNY4tcGsWqWkEAHSLKE/A435qnrWn8AD8B8Zyv6t+6/i+Bgv6XKlxBAAgh7qpv50xRrcM3lLz2i2DtwTexMT91DxLT+GBbucdGOup65/S8KphjU2N6fYnbtft+2+vuy5LIy5nUdDnmsZnR41jDKhpBIDu1m397XY8uUN7D+2teW1o15A2rNigm153U933xP3UPEtP4YFu5zcwlqTKwFh+6/i++mv0ubb7syNxBACgBdX97STVTEExvGq45Qmws6ZUKmnvob2anpnWQP+AxjeNa2jXkKZnpiVJN665ccG8aXFP08G0H0D2+A2M5S4HrYO/Rp9rO5E4AgDQgm7rb1coFLRhxQZJ0vTMtNbct0aSNNA/oA0rNtSdbDvup+ZZewoPoLEok9h7H7xVL/utC3pP1GO1i18Zonx2STDNtI0dHBy0ExMTCRYHSWDwHiTJGHPAWjuYdjniRKxDFNZarb53dWX5qeufSuXiHufNT9C+SqVSJWmUpIPXHaybNCZVtiT2F4RYBwSLu8l+0P4k1V03fWRaA8sHmi5DFrobZKEMLr94x+A4AAC0yK+/XbsHLhidHK05rluu0cnRWPdlrdX2ie0122+f2N7wfON+ap6Vp/BAt4t7ipyg/R2dP6qjx4/WXTc3P9d0GbIwvU8WyhAGTVU7mFvT+PjzR2qWqXkEgPhkpb9dnH0tg/Z17cC1uv2J27Vzaif9CwFIav+UO+423nW3DN6i7RPbmypDFrobZKEMYdBUtYN5E8cLz1kuicQR8aL5FpCdJkbVSawr6o1H0L7uPHhnJs63nYh1QGNxN9kP2p/fuqhlyEJ3gyyUQaKpalcav2G9xm9YrwvPWa4Lz1leWQYAxGvr2q01yZn79DhMEhVl/ke/98Q5t2HQvrau3Vozb6M7r2OnJo0AGou7yX7Q/vzWlUqlSGXIQneDLJShERJHAABiEKW/XZQ+iY36HsZ14xG0r9HJ0Zo+jW6fxyh9KQHkX9wT1Qft7/Ynbtft+2+vu25o11DTZYi77FFkoQxh0MexC1DLCADZE6VPYrv6Hgb127TWSkbaObUzdLkBdLZ2T7kjqe666SPTTZchC9P7ZKEMYdDHEUBL6PcDRBelT2K7+h4G9du8cc2NsfWlzAtiHdBYO6fc6aZ5HNvNL96ROAJoCTdTQGuiDIZQLBa1dmxtZXlyeFI9PT2V/cV1M9Xopi0Lgzi0C7EOQLdgcBwAADImSp/EzV/crI33b6x5beP9G7X5i5sl1e9rGXV+R79+m3kYxAHIuqCBsaIMmpV1pVIpcBn+ov49xP13ROKYovNvfVjn3/pw2sUAAKQgymAIxWJR337p25o5PqP+Jf2aHJ5U/5J+zRyf0bdf+raKxWLd48Q9MXceBnEAsizoYU7UBz1ZtmX3Fg3tGqoki6VSSUO7hrRl95aUS5Z9Uf8ekvg7InEEAMAjylPaoKfp9db5DYYwvGrYdzCEnp4evePn36H+XidZXDu21kkie/v1jp9/R6W5arXq/Y5NjWn1vatrBr2Ja9CKoHIDOCXoYc7R+aM6evxobA96sqBUKmlufk7TM9OV5HFo15CmZ6Y1Nz9HzWOAqA/+4n5g6KKPYwrcWsbZYyclSX1LncFtn7710tTKBERFvx90mqBBYfwGmNmye4vm5uc0vmlchUKhcmO0rHeZJPmuu/uyu5vuezg6OaqXjr2kv332byuvvfM179TpS08PHAAniYm5szCIQ7sQ6xCnoEGuJHXc4FPVyaJroH+gEhfhL8ogaq28T6KPIwAADUV5Shv0NH12flZHjx8NfNLezPyP1lq9dLw2aZSkv332b/XS8ZcazlNWrdVmpVHmrQTgqJ5uweXe0Aety6tCoaDxTeM1r5E0hhP17yGJvyN+Wyl4+tZL9fStl6pv6SL1LV1UWQYApCtKs073hmigf0DTM9Nac98aTc9Ma6B/QJ/Z9Bnd/2v3110X5abJWqsDPzhQd92BHxyomwjSJxHInqCHOZ04+JT70KxadZ9H+Iv695DE3xGJIwAAVaI8pQ16ml4oFPTpyz9ds+7Tl3+6kjQ205+yUCior7dPr+l/Tc3rr+l/jfp6+1QoFOq+nz6JQHYEPcy5/Ynbdfv+2zvqQU91S4uB/gEdvO5g5WEayWOwqA/+knpguKiVk0FrqGUEgOzxe0oblDz6PU0f3zSuOw/eqfFna5PKjfdv1NBrhmSMabo/5Scv/aRu23+bnp15tvLaG858g96/7v2B/TOry+8mjySNQPv5DTAlOQ95JPmuy+N3tlAoaFnvspqWFuObxit9vWmu6q/R34rf30PU9zUsD4PjAGgFA0agk3if0m67YNuCZe8F1/s03b0hmp6Z1s+f8fP64X/8UP8+/+/qX9KvPVfv0cb7N1am07jsZy/T333r70IfK6h81666VrLSzumdofeH8Ih1iFvQAFOdOPhUqVSqSRK9y/AX9e8h6vv84h01jkAHihIoOvEiBTQrylPaRk/T+3r7KnMvrh1bK0nqX9Kvc08/Vx944wfU09Ojsamxysh3QUleo/LduOZGGWNC7w9AeoIGmPJbl4XkK2rC6y1nJyeNcd9TRR2MLO5BzKhxbMLPfeAhSdJzH7k85ZIsNHTXY5Kk8RvWp1wSpC3KVAJR3uPiKTw6UZQbo6AbumKxWEkaJWlyeLIy52KUaTIala/e/ng41BpiHdIWNO3P3Zfd3ZYyBN0vSIp8L9FJWrmnygqm4wC6QJSpBJKaJBbIM7+ntKOTozUDC7jfl9HJUd+n6dZaffTAR2vWffTAR1saPdGvfH772/HkDt9yA8i+oGl/3Kl9khZ0v3B0/qiOHj/a9fcSnX5PRVPVENyaxqKtXc5CzaNb0/j480dqlql57E7VzdaaafrW7HuAblR9QyBpQR/CejV4QX0Sraxvn0R3/818/4KO5Y5gGLbcALKlugm8O7WPpMhT+0TR6H7B3aab7yU6/Z6KpqoheBPHnvLvPIuJ44XnLJdE4tjtojZ9a/Y9Es230F2qkzNXoxuCdjbt8jvWssXLNHdirqlyoxaxDllQKpUqSaMkHbzuYCp9HP3uF6LeS3SavH8OfvGOxLEJWapp9KKmEa4oN7ZR3uPiZgrdJsoNQbFYrPRp9C7H3ffQb395v5FJG7EOaatunupqZ42jFHy/ICnyvUQnaeWeKivo4wh0gSgTviY1SSzQiaL0Sdyye4uueeiaSh+kUqmkax66Rlt2b5GUwKh3dfYXtS8lgGzwTvtz8LqDlSbobp/HpAXdL9z+xO26ff/tXX8v0en3VPRxbEIWaxpd1DRCijaVQFKTxAKdJqgPoVS/T6J3QIvqPkoD/QNtGUo/SrkBZEujaX/a1ccx6H5BUtffS3T6PRVNVYEO1M55HGm+hW4SZZj1LDQv64Th4dNGrEMW5Hkex26S98+BPo4AEsHNFLpNlBuCoAEt2vWgJ+83Mmkj1iHroiR0cc9ZG3dSmYW41Y2Jsl+8o6lqE6IMQBP0Hga0AYD8abZPolvjWM1ttvo/nvofTdcERq09jLsvJYDsiDJ68/SRaQ0sH2jqPV/+7pd1eu/plRYTbnxb1rtMF/yXC2IdQToLLSXaOSp2HjA4DgAACQka0OIdX3hH0xNmd/rk0gCaVxMXHr1Z9qsf1cijN2tsakxH54/6xpm5+bm6rwe959jJYzUD8rjxbfb4rO97gvaX5VgXVIYo59QJaKoaQpS5EoPew9yL6CQ030IWtHO6Cz9+x9mye4vm5ufqPqH/5KWf1O1P3K6dUzsr77t21bV63wXvi336nE5tUtUuxDpkmbXWSRYPP1J5bfjsS7Tt4j+XVH+ajFsGb9H2ie1NTa3x+2/4fV3z0DV1+2wbY2KdqiML01p06/QjTMcBAOhIb/3sW7Xx/o0qFouSnKRx4/0b9dbPvlWjk6M1Q6C7NwGjk6OxliHoOHdfdnfNQDjuaIh3X3a37jx4p+R9fmvlvO6jepQ+V6MblXZ9DgDSYYzRtsVn1by2bfFZMsb4xoxCoeAbS/ze09PTo/FN4zWvu/EtKDZFiVtR3hO3uM8p70gcQxi/Yb3Gb1ivC89ZrgvPWV5ZjvqeKPsDACxULBZ17OQxzRyfqSSPG+/fqJnjM/rPE/+pl46/FNyU6NB+ad8dzs+IwjSp8o56WCgUZK3V0eNHtXN6Z826ndM7dfT4Ud+mTs3OyZiFJl8AkmWt1ciJF2teGznxoqy1vjGjVCr5xhK/9xSLxbp9tkulUmBsijKXbBbmn437nPKOwXEAALnV09OjPVfvqSSLa8fWSpL6l/Rrz9V7VCgUVDAFjU2NVZoTVZoSHX5C+tQVUnFe6umV3vWgtGJd02Wofupc9zhBT5/9Vvm8HmVOxpbKByDzKnHh8CNO89TFZ2nkxIsaO/yI7BO3S9Z5IOWNGRPfn9D0zPSC162s73se+vZDmjk+U2me6vZxfMcX3qHB/zJY9z1B+5Pqx60szD8bVIYo59QJ6OMIoCX0+0E7+fXTKxaLlaRRkiaHJ2v6OK6+d3Vl3VPXP+WMgPfVj8rs+TPJFiXTI7vxv8v88u9HLlvQlBt+RidHdXT+6II+jqf1nhb7SIN+nwPCIdYhyxhVNTufayeMqso8jgASwc0U2sXvAv6TPT+p+//3/Zo5PlPZtrrGsd7gBcsWL9Pckf+jbY/9nUxxXranVyPrf0t9P/V/Rbrg73hyh/Ye2rtgwIgNKzboptfd5Ps+a61u3397TXPVaweu1fvW+Q+O476vmYFusjDIRN4R65B1zOOYDOZxPIU+jgCAzAvqp/epqU9p5viM+pf0a3J4Uv1L+jVzfEYbPrNBt+2/rdLM6Knrn9LwqmGNTY1p76G9Gjv8iEbW/5bsxv+ukfW/pbHDj0Tq81cqlSpJo3fKjb2H9qpUKvme08gTI5WmTm75dk7vbNhPxhhT0z8zbNLo/Rw6vT8O0E2C5mr1WxflPfX6bLdShiBZmH827nPKM/o4AjHr1KdPQJqC+ul9+Ttf1rHiMe25ek9Nn8eli5bq9CWn19SsuftYtniZBv/LoLOv8jGi1sAVCgVtWLFBkjQ9M11prurWOPo1VzXGqK+3r275+nr7gstxaH/o/pktHQfIAa67QHvkpqmqO/dh0qOPtus46ExZaI/fbjTfQtwaNQuq108vyjyOQX3+otyIBvWzjHq+vvbdIT364Ur/TF38Qemi98Z/HFQQ67KpG6+7QNJoqgokjCHvgdYFzTcYNPS5N0GrXq7XlChoX1HmPNzx5A5d89A1Na9d89A12vHkjobnHKmp08qLnJpG0+P8XHlRMscBMozrbpeIYdokxCPzTVXdGsDHnz9Ssxx3jWC7joPOxZD3QGuqbwIl1Qxvfu2qayuDyLQ69HngEOvWSkaVUU6r1w2vGq5bS1fTx3HZCo2/fKOGfrynMlDOjWtubDi6atNWrHOap76wz0kaw04jcmh/8+8BMorrbhdoolk+kpf5xBHIE/ciVj1yIRcvIJxGN4F3Hrwzln56jfr83bjmRhmZ0DeilT6OJ/4/Tc8d0pq5eyVJA8tWBPZxbNmKdc3dQHEDhg7EdbfDvbDPiVm26Px8YR9xK0X0cUzpOOhM3TjkPf1+ELe4+x76aTSkfLNlKH1lu9a8cG/l9YMrr1fhzbdEKlsiIvSLxCnEumzqxutuV+GBVyro4wgkjCHvgdYF9T2U4uunNzo5qu0T22v6MW6f2N6wL6Vf/8cdT+7Q9pPfq3nP9pPfy9b3PkK/SCDLuO52AbdZ/sUfJGnMgNw0VW1XDSA1jYiKIe+B1gT1PZRabH5W1bfPnn1BpL6UVlay0s7phf0f3Xkbh8++RNsWn6WREy9q7PAj0hMj6dR81OvLGLVfJJBRXHe7RLPN8pGY3CSOQB5sXbu1phmbexHj4gU0lthNoKepk3nXg5H7Ut645kYZs7D/ozsvZOU91krlKQFSSRr9mnZxA4YOw3UXaJ/c9HEEkE30+0HcYp9v0KdvX9S+lH7vy8w8ifRlTASxDuhOmYntbUQfx5DOv/VhnX/rw02tG7rrscqgOnGIe38AkCexzzdYp29f1L6UQe/LzDyJ9GUEgFhEmde3k5E4AgA6m2dwBXv2BeEG1Ji4R7rvKuenQg7E0c6Jqv2OFXUwCSbZBjqbJ6a1pAviRfXcwm6Md68Bs/OzXTn4En0cy9yaxNljJ2uWn771Ut91573yNEnS488fkdT6VB7u++PaHwCgrKpvn5Ea96WcuEfa9W7nvc896rxvcHPw+w4/0b5h4xsNUc8cjwCq1YlpGtwcbV9dEi8azS3c6c1V6yFxBAB0nYYDakw9UPuGqQekwc3B79t3R/smqo57Umwm2QY6m09Mi6SL4oUb46vnCe3WpFEicax4+tZLJdXWNIZZJ8VXM+i+n5pGAEheYJ/EVVeeeirvLjd6n9u30H0K30zfwnrTZwS93sqx6ol7fwCyJSCmNa2L4oVfv/ZuTR5JHAEA8DrzPKmwWCqdcH6eeV7j90SdJ9Gv2VejaTXinJOROR6BzubWLk494CSNUWsbpa6JF4nOLZxTJI4e3trEMOvirhmkphFAHLpxCPHYvLBPsiXn/7YUvilWlHkS/Zp9NWoOFvecjMzxCHS2wc2tJYzVuiBeJDa3cI6ROAJABxqdHNXs/GzlYuc+Oe3r7dPWtVvTLl72tbMplt+xuqg5GABkUcP+8F2GxBEAOkz1EOKSaprXDK8abn/No18/vajvibI/PxP31G+61agpVpzn5HesLmkOBgBZlpk5ejOAxBGx8WsWR3M5oL0yNYR4lGHbg94T5zDwjYan92uKFfc5BR2rC5qDAUhenPdi3Nd1r0LaBQhr6K7HKqONhnX+rQ9XRkKN4z1+ZYhStqjly6rRydGaibPdZnFbdm+p+/ro5GiaxQU6XnXy6EqleU29fnqtvCfK/vzUG54+jLjPCQAS5HePFuVeLM59IX9ykziizQ7td+YkO7S/4abVzeLcYOI2i5ubn6v7+uz8bCXoAIif3xDibf/euf30TE/4fnpB74myPz/e4ejDDk8f9zkB6AxN3Du19J4m9ldzj/bozbJf/ahGHr05/L1Y1f5C7yvonNr1GcX9uUKSZJq5iRgcHLQTExMJFmchtybv8eePSJIuPGe5pOCRR91avNljJyVJfUudFrlBI6YGvcevDK5myha1fG0VoRlWdVLoGl41rFsGb9H2ie0LXu/mjsWdxhhzwFo7mHY54pRGrItT0BDiqTVXbWaOwlbWNcuvj2MjcZ9Ts8eJuj9ERqxDoCSasMdUBmutk+AdfqSy6fDZl2jbxX8efC2osz979gXB+4q7q0EWPtcu5Bfv6OOIhRoNAV+H2yyuOkGsHrq43usAkpG5IcTr9dOL2uev0bpmRR2ePu5zqqddfT0BtC7CvVOk90TYnzFG2xafpbGqTbctPqvxtaDO/syKdcH7Cjqndn1GcX+uqMh84ujW3rm1fmHmOHRr7tyavTA1eUHvaVSGZsoWtXxtFWEIeL9mcW6No/d1kkcgWZkfQrwTL+xtuglM5FgAWhNl+py4p9zx2Z+1ViMnXqzZdOTEi9rWaFCbOvtruK+gc2rXZ8RURonJfOKIFDQ5BHxQs7iJ709oemZ6wesSNY9A0jI9hHgnXtjbdBOYyLEAtCbK9DlxT7lTZ3+Ve7TDjzhNShefpZETLzpNTRs9yPfsz559QeN9BZ1Tuz4jpjJKTOb7OCIf/CYbnz4yrYHlA0xC3sHo94PI8txHjz6OXYdYh7zyu0eLci8W576QXX7xjsQRsWEex+7EzRS6DoM1dCViHfKMeRzRDL94x3QciE0WmsWVSqXAZQBoGfM4AsgZv3s0bwVSmAqlLNzvIR0kjh5Ddz1WGeymmXWor50TxW7ZvUVDu4YqyWKpVNLQriFt2b0l9mMB6GLM4wigA7TzHg2dgcFxkJjqiWI1+/2aTtTDq4ZjbdpQKpU0Nz+n6ZlpDe0a0vimcQ3tGtL0zLQG+gdUKpVUKPCcBMiNoP57UeZejLM/IIM1AJ2vw/sQ19yj/eAZbZt5SSP9p2vsyDdjv0cLpZ3z+nb47zZJJI5lbk3i488fqVkev2F94Dr4q8wdN/t9jR1+pDLnz/DZl8Q+omqhUKhJFtfct0aSNNA/oPFN4ySNQJ4E9QecuEfa9W7n/8896vxslDwm0b8wylyScc4/CSA5XdAnuXKP9oNnNHbkm8492hFpePnr2z/qfdQ5a+lv3nbcTSNR7qSz1UJNOhuBmzxWI2kEciioP+DUA7Xbepeb3R8AeHVJzDDGaNvMSzWvbZt5qf19FoM+76jrohwLDVHjWObWHtarTQxah2CRJ52NwO3TWM1ttkryCORI0ByFq648VdPoLreyPwDw6pKYYa3VSP/p0pFTr430n57IPVqgqHPWRvk9dcnvNikkjkhMS5PONslNGt0+jdXNVkkegZxZsU667LZT/RirmxENbpZmnpemHpRWXVHbTNWv3wr9CwE0owtiRuUe7cg3neapVX0c475Hayjo8466Lsqx0BCJo0dQbSI1jc0xxqivt0/Dq4YrAWibtVJ5oti4+zgu611W06fRTR6X9S4jaQTy5NB+aff7nSfC33lMOvO82j4tj9/lrHv8Lmngcmddo34r9C8E0IwOjxntvEcLJejzjrouyrEQiMQRidq6dmvNyFxuZ+wkAtLdl91dM3qqmzySNAI5U68PinuR91sX9B4AwALtvEdDZ+COGokLmig2aOLZKJPSepNEdznu4wSJe39Ax5q4R7rvKudntaA5D/3WrbxIKvRIMs7PsP1WDu2X9t3h/GxmHQB0gKB7NMCr7TWOUQeY8Xvf+bc+LEl6+tZLYygdA+C00+jkqGbnZytPt9z29n29fZLku27r2q2ZPE6jY0XZH9CxgqbViNynxXh+NhD3MO8AAHQwahy7XUpP1Ksnnh159GbZr35UI4/erLGpMR2dP6qjx486654YOdWBe2pMs/OzTdXg1RzHs6/Qxwn5GQUdq9lyAx2v0bQaK9ZJF723frJWb90L+6TSSUnW+dnqsOwM2Q4gLn6tKyTpH/9I+svXOT+bWRenKC0v4m6tQQuPXGhbjaNbk/f480dqlhvV7Pm975l/PSpJmj12UlLrNY9Ry5drKT5Rr0w8O/t9jR1+xJl4VnJGX73gfZVtxqbGNDblrK3uwN30caS6+2p4nCY+o0bHovkHUCXKtBpB4h6WnSHbAcQhqHXFP/6R9LWPO/93f77lQ43XxSlKy4u4W2vQwiM3qHHsZik/UTfGaNvis2pe27b4LBljapKwyrqIyVfQvhoep8nPKM5yA5kT5xPhwc3Spr+Qfu5i52f1tBpRjuVO4XHum52fzQzLfvEH64/C6rcOAMIKal0x9aBn3YPh1sUpSsuLuFtr0MIjN9pW4+jW3DVbk9fofXH1cYxavlxL+Ym6tVYjJ16seW3kxIvOcNCSRp4YqV0XcV4ht8lovX01PE6Tn1HQsUgekWtJPBEe3LwwYYx6rKApPILEPcw7AFQLal2x6opTtYnucph1cYrS8iLu1hq08MgNpuPoZilOglrp/3f4Ead56uKzNHLiRY0dfkT2idslK+2c3llp5un2FZSaq8Gr7mfo3ZeVbXycJj6joGM1W24gc9o53UWUYzEdB4Asch+OTT3gJI3VD8vcpqdTDzqJYXVT1KB1cYoyGFnkAcwilAGZYpoZsGNwcNBOTEwkWBx0E0ZV7QzGmAPW2sG0yxEnYl0d7eyDQh8ZZBCxDkC38It3JI5IVfXEs97loHVZPU4S+8s6bqa6yKH98T4RDtpflGPFXT6gCrEOQLfwi3c0VUWqgiaejXNS2nYdJ4n9AZkRZ5+/RjWEUY5Fn0QAABLDqKpIlbfGu9W5DqPsr1QqBS4DSACj6AEAkCu5SRyH7nqsMuJpq+/5uQ88pJ/7wENxFQ0RjU6OauSJkUpy5/YHHJ0cbdv+tuzeoqFdQ5VksVQqaWjXkLbs3hKpDABCckfRMz2MogcAQA7QVBWpsNZqdn62ZsTR6hFJm+0XWLO/HzyjbTMvaaT/dI0d+abv/kqlkubm5zQ9M62hz2/S+Ms3aujHezQ9d0gD/QMqlUoqFHLzbAXIF3feRXekQZqYAuhUUftf+71v4p76o7S2u3zoOplPHN0aw8efP1KzHDTPot97Jl5wlovl1otureNzH7k85lKjEWNMZR7FsamxSgLpTmPRbL/Ayv5+8IzGjnxTY5J0RBpe/nrf/RUKBY1vGtfQ5zdpeu6Q1szdK0kaWLZC45vGSRqBJEWddxEA8iTqiM9+75u4R9r1bmcbd37IVpJHRqRGE7gzRmqqk0dXK3MdGmO0beal2v3NvBS4v0KhoPGXb6x5bfzlG0kagaTRxxFAN4ga6/zeN/VA7Xbe5XaVD10p8zWObs1imJrGsO+hpjEb3D6I1UaeGImcPFprNdJ/unSkan/9p2tbQLPXUqmkoR/vqXlt6Md7NF56L8kjkCS3j6P7lJs+jgA6UdRY5/e+VVeeqml0l9MoH7pS5hNHdCY3aXT7NFb3cZSar3ms7O/IN53mqVV9HOWTjLoD4UzPHXKap1b1cRzaNURzVSBJK9Y5TaLinMcRALKmUaxr9n1us9S4+jhGLR+6Um4SxzA1jWHfQ01j+owx6uvtq+nT6DZb7evti9THccH+rJWeGPHdX6FQ0LLeZRroH6gkieOl92po15CW9S4jaQSS5jfvIn1uAHSSqHPM+r1vcHM8g+I0Og7gkZvEEZ1n69qtNaOduslj1D6OUfZ392V314ye6g6YQ9IIpKhenxtuagAASBV3x13Mne/Qu+z3eqN1UXiTuurlYrFYs8673IygcnuTxDBJYzs/oyyXATl2aL+07w7nZ9Y0muMxy2UHAKBDJVbj6DcwTTOD3LTq/FsfliQ9feulocvQzvKlaXRyVLPzs5UaObeP4PSRaQ0sH1jwel9vnyTVfU9fb5+2rt0aa/ne+tm36tjJY9pz9R719PSoWCxq4/0btXTRUn3p7V+K7ZyilNvvOO38jLJQBuRY1puCBvW5yXrZAQDoUNQ4pinKU/OJe6T7rnJ+RtyXtVaz87MamxrTyKM3y371oxp59GaNTY1pbn7Oef2JkZoBbI7OH9XR40frvmd2fjbWGq1isahjJ49p5viMNt6/sZI0zhyf0bGTx5yaR8/5RjmnKOWuOY73Mzp+VEfnj8Z2rCyXATmXh+HXV6yTLnrvwqQwD2UHkA/tar0QdBxaUCBHTDM3koODg3ZiYiJwG7fG7vHnnTkRLjxnec167+tJ1Oy5NY2zx05KkvqWOhWr573yNN8y+JU7sZrHKE/Nqyd9laRNf+F0jo6wL2utk1gdfqTy2vDZl+iWjXdo+8T2yuimkioDzkiq+55tF/955H6JfqqTRVf/kn6nBvJ7B+qeb5RzijztR9UIsNX7k+S7Ls7PKAtlcBljDlhrB2PfcYrCxLpcy3OtXZ7Ljlwj1nWYdsWSoOMQz5BRfvGOGse0RHlq7jfpa4R9GWO0bfFZNa9tW3yWCoVCJfmovF5OOPzek0Qy0tPToz1X186v6DZb9TvfKOcURfUIsN79Ba2LUxbKgBxzm4Je/MH83ajkuewAsqNdrReCjkMLCuRM7H0c3Rq6NPs4un0am+nj2KjcsYsy4arfpK8R9mWt1ciJF2teGznxom4plbR9Ynvt6+V5EN1tvO/ZVjWSaVzcGsdqG+/f6CSPPucb5ZxaqXGstz/3/3EdK8tlQM7lefj1PJcdQDa0a+L7oOO0qwxATJiOIy1RJlz1m/S1yX1VmjkefsRparr4LI2ceFFjhx/RxK4hTc9MV5o2uk0eraxkpZ113qOYk5LqZqpu81R3uZI8es43yjlJzdfEVTcRXfAZWSsZaefUzliOleUyAACQa+2a+D7oOO0qAxCT2Ps4Ih8YVZVRVeNCvx8A3YBYB6Bb+MU7EscuZj1NTN1lv9eD3pOEYrHo9Gn0Wa4nyjlFkYXPKAtlkLiZyrxD+/2nteApNxAasQ5At/CLdzRV7WLeRMJd9nu90To/UZMYb5LYKGkMKl+Uckc5TqN1cSZ0cf+e0IH8RuxjJD8AANCkto+qOnTXY5UBaND5RidHK/MJSqf6541OjqZcsvbjs0Db+Y3Yx0h+AACgSUzHkTd+E8XGPYFs1Mlqq9YFTVRfMxl9lLLnbMLc0J8FECd3xD7TUztin9/rAJBXfvcFE/dI913l/ExL1HuWuO/5cnbvhOxpW1NVt5bx8eeP1CwnPu1FJ2lXs7Ook9V61pl3PViZHmJsaqwysmfNZPRRyp7DZnbVcyv6fhZA3PxG7GMkPwCdxO++YOIeade7nW3c6czcEenTLlvU98W9P6AJ1DjmSbuanUWdrLbOuoaT0Ucpe06b2TX8LIAkrFgnXfTehTcIfq8DQN743RdMPVC7nXc5zbJFfV/c+wOa0LbEcfyG9Rq/Yb0uPGe5LjxneWUZTWhXs7Og/TW5zm+i+krTzChlz2kzu4afBQAAaJ7ffcGqK2u38y6nWbao74t7f0ATGFU1T9rV7CzqZLWedfbsC3wnqpfKtW1Ryp7DZnbVfRp9PwtqHgEAaJ7ffYHbLHXqASdpbHcz1aCyRX1f3PsDmsA8jkhU0ET1SUxGn2Wd+lkwtxmAbkCsA9AtmMcRqdi6dmvNXIVuP79urF3jswAAAEBeMTgOEsdk9KfwWQAAACCPSBxzxNusOEwz4yjvicrvWEFlKJVKNeu8y90i7t9TO3/v6EDM9QUAADxoqpoTUfrHtbNPnd+xpo9Ma2D5QN0yPPH9JzQ3P6fxTeMqFAoqlUoa2jWkZb3LdPdld8daviyL+/fUqX0p0SbM9QUAAOqgxjEHrLWanZ/V2NRYZfoGd0TO2flZpzZp4h7pvqucn2HfE1UTx5qbn6v7+tHjRzV7fFbTM9Ma2jVUSRqnZ6Y1Nz93quYxzpqPDNaixP17SvT3ju7AXF8AAKAOahxzoHri+LGpscoUDu60DubAp6Rd73Y2fu5R5z2Dm4PfE7Vv3cQ9TR3rlsFbtH1ie90yWGsryeKa+9ZIkgb6Byo1kLHWfGS0FqXh77bJ31Pc+0MXcuf6cr8rzPUFAABEjWNuVCcErkoiMPVA7cbl5cD3RNXksQqFgm8ZCoWCxjeN16yrJI1SvDUfGa5Fifv3lMjvHd3Dnevr4g9m5gELAABIH4ljTrhNDqu5TRG16srajcvLge+JqsljlUol3zK4zVOruc1WJZ2q+TA9rdd8xLmvmMX9e0rk947usmKddNF7SRoBAEAFTVVzoLqfmtvk0F2WyrVJklP7t+pKaXBzuPdEqYEa3Oz8DHmsie9PaHpmesHr1lpNfH9Cz/77s5XmqW6z1aFdQ07No1vz8cI+J9Fr5SY2zn3FKO7fU2K/dwAAAHQ1EsccMMaor7evpp+a2xSxr7fPSQQGN59K6sK+J6omjjV9ZNq3DH1L+mr6NLrJ47LeZaeaq65YF1+SF+e+YhL37ynR3zsAAAC6lmmm+drg4KCdmJhIsDgIYq2tufH3Lsf1nrjLF1SGUql0Kkmss9wt4v49tfP3bow5YK0dTGTnKSHWAfAi1gHoFn7xrvvu0HPMe+MfJhFo50TwUcoX5T2dKO7Pgc8VAAAAcaKpagfbsnuL5ubnKk1B3cFolvUu092X3d2WMgRNRi+JieoBAACAHKDGMQ7tnFg+5LFKpZLm5uecwWY+c4lKn7pSQ5+5RNMz05qbnzs1cmmLxwkSNBn90fmjOnr8KBPVAwAAADlAjWOr2jmxfBPHqgw285lLNH38R1qjH0nHpYElr6idKzHBc2o0Gb27DRPVAwAAANlGjWOr2jmxfJPHKhQKGj/eV/Pa+PG+xoPPxHhOQZPRM1E9AAAAkA8kjq1q58TyTR6rVCppaMlszWtDS2YbN1ON8ZyCJqNnonoAAAAgH2iq2qp2TizfxLHcgXCmj//IaZ56vE9DS2Y1ffxHGto1FNxcNaZzCpqM3spKVto5vZOJ6gEAAICMI3GMQzsnlg95rEKhoGW9yzTQP1BJEserRlVt2Fw1hnNqNBm9JCaqBwAAAHLANNMskIli86dUKtUkid7ldgiajL6dE9UjGUyKDaAbEOsAdAu/eEcfxw7nTRJbTRq9DxrCPHgImoyeieqTEeX3BAAAAPghcURoo5OjNYPXuH0YRydHUy4ZqvF7AgAAQNxIHLPo0H5p3x3OzzjeE2V/HtZazc7PamxqrJKUuIPZzM7PUqOVEfyeAAAAkAQGx8maQ/ulT13hzJ/Y0+uMbtpokJqg90TZXx3Vg9eMTY1VRj+tHtwG6eP3BAAAgCRQ45g1L+xzkjxbdH6+sK+190TZn4/qpMRFMpI9/J4AAAAQNxLHrFl5kVMzaHqcnysvau09Ufbnw232WK26Lx2ygd8TAAAA4kZT1axZsc5pTvrCPifJC9OsNOg9UfZXR3VfObfZo7ssUaOVFfyeAAAAkAQSxyxasa75BC/oPVH252GMUV9vX01fObc5ZF9vH8lIRvB7AgAAQBJIHBHa1rVbZa2tJB9uUkIyki38ngAAABA3+jiiKd7kg2Qkm/g9AQAAIE5dlzh6BwjphAFDsn5O7Sxf1j8LAAAAII+6KnEcnRytGV3SHUhkdHI05ZJFl/Vzamf5sv5ZAACA9hq66zEN3fVY2sUAOkLXJI7WWs3Oz2psaqySXLijTc7Oz4armTq0X9p3h/MzSUHHqVoXyzklqKZ8j94s+9WPauTRmxMpX9Y/CwAAACDPumZwnOrRJcemxirTE1SPPhno0H7pU1dIxXlnPsR3PdjySKVNH8ezzrzrwdbOKWGVz3z2+xo7/IjGyq8Pn31J7OVr+fcLAAA6hlvL+PjzR2qWx29Yn1qZgLzrmhpHqTa5cIVOKl7Y5yRstuj8fGFfMoUMOk6ddS2dUxsYY7Rt8Vk1r21bfFYi5cv6ZwEAAADkVVcljm7zxWrVfeICrbzIqQE0Pc7PlRclU8ig49RZ19I5tYG1ViMnXqx5beTEi4mUL+ufBQAAaI/xG9Zr/Ib1uvCc5brwnOWVZQDRdU3iWN3nbXjVsJ66/ikNrxqu6RMXaMU6p9noxR9Mrplqo+N41tmzL2jtnBJW+cwPP6Lhsy/RU+e8S8NnX6Kxw4/EXr6Wf78AAAAAfHVVH8e+3r6aPm9us8a+3r5wzRlXrEsuYQx7nKp1Rmr9nBJU9zO3VnpiJPbyxfL7BQAAHYVaRiA+ppmamMHBQTsxMZFgcZJnra1JIrzLeZT1c2pn+bL+WXQiY8wBa+1g2uWIUyfEOgDxItYB6BZ+8a5rmqq6vElEJyQVWT+ndpYv658FAAAAkEddlzgCAAAAQ3c9VpmmA0Bj3Zk4Htov7bvD+ZlFE/dI913l/AQAAACAlHXN4DgVh/ZLn7rCmQexpzfZEVKjmLhH2vVu5//PPer8HNycVmkAAAA6ilvL+PjzR2qWGUgHCNZ9NY4v7HOSRlt0fr6wL+0S1Zp6IHgZADzibm5F8y0AAODVfTWOKy9yahrdGseVF6VdolqrrjxV0+guAwAAIBZuzSI1jUBzui9xXLHOaZ76wj4nacxSM1XpVLPUqQecpJFmqgB8xN3ciuZbAADAT/cljpKTLGYtYaw2uJmEEQAAIEE8FAOa052JIwB0gLibW9F8CwAA+Om+wXEAAAAAAE3JVI0jT7kBoHlxx0xiMIBOEXRvef6tD0uSnr710liO9XMfeEiS9NxHLo9lf9wXI2uocfQ6tF/ad4fzs5vLELdOPCcAAACgS2SixjEzI/kd2i996opTU3W868H2D6KThTLErRPPCehgccfguJ/q8xQeQCNB95ZuTJo9dlJS6zHKrWks2trlqDWPmbkvBjyocaz2wj4nubFF5+cL+7qzDHHrxHMCAAAAukgmahwzM5LfyoucGjG3ZmzlRd1Zhrh14jkBHSjup9xxP9XnKTyAsILuLd0YFFdrCLdmMa4+jpm5LwY8MpE4ZsaKdU4zyhf2OclNGs0ps1CGuHXiOQEAAABdxFhrQ288ODhoJyYmEiwOgLwxxhyw1g6mXY44ZTHWxT0yYNCT8bj7JNLHEZ2AWAegW/jFO/o4AgAAAAAC0VQVADIs7pEBg0b/c/ft7i+umr24ahpd1DQCANB+1DhiAW/z5WaaMwMAAADoPNQ4osbo5Khm52e17YJtMsbIWquRJ0bU19unrWu3pl08oON5a/laHRnQ25fR/bny/Qv7OLr7dtd5a/aCjhN3H8wg9HEE8iHouxrlexz3e+KOTXEj1iFrSBxRYa3V7PysxqbGpNnva9viszRy4kWNHX5Ew6uGZa2VMSZ4J4f2M3oqAAAA0GEYVRU1rLUaefRmjR1+pPLa8NmXaNvFfx4uafzUFafma3zXgySPXYCRBuPh7ct44TnLJUV/0uzty9hT/voOrlzuexy/9/zkEucZo9v3sW+ps/z0rZcGltvbB7P6fVHE/RkBzSDWhRf0XY3yPY77PXHHprgR65A2RlVFKMYYbVt8Vs1r2xaf1ThplJyaxuK8ZIvOzxf2JVRKIPuG7nqscvFP2vm3Ply5EcqTdn5GAACgNTRVRQ1rrUZOvFjz2siJF7UtTDPVlRc5NY1ujePKixIsKdBZ3CfJbq1fq0+Wg/oy+h0n7Huqn8q32gezGUHHApAdQd/VKN/juN8Td2yKG7EOWUXiiAp3IJyxw484zVOr+jjqiZHKgDm+VqxzmqfSxxFdLGj6jCDuDYzbTDTMDU3QdBzemjx3+Zl/Pep7HG+tpbt83itPq3lPqzczUT8jAACQHhJHVBhj1Nfbp+FVw5UkcZu1UnlU1VDNVVesI2EEulBQ0sc8jkB3CvquRvkex/2erNU0ehHrkDUMjoMFvKOnhhpNFV2LASPq806DUS3K8PBRh5T3e19Q+aKUIYjf+7LaTAyoh1gHoFswOA5C8yaJJI0AAABAd6PGEUBLeApfK2iY93YNQx+kncO8+x3LxVDzyBNiXX1BrReivC+oJUKUlhzuYF8v3LbwPXG3vPB7T9ytK+gXjqRR4wgAAAAAiIQaRwAt4Sl8fVH6HQaJ+wlzO/sX+pU97nPiKTySRKyr5dbWuaMt95R7tTSqefR7308ucVpn1GutEXQsv5YN7rLXC7ddHrg/v1Yj7ujS9VpK+L3HVe+comhnixF0N2ocAQAAAACRUOMIoCU8hc+XTnxi3YnnhOwh1tVHH8fG76GPI/KGGkcAAAAAQCTUOAJoSbc/hc/rk9+8ljtIJ54TsqPbYx2A7kGNIwAAAAAgkkWNNwEAeHn71eWttisv5WxGJ54TAABZQY0jAAAAACAQNY4AEIFbu8VchAC6QRZiU1AZoo7uGuVYQLeixtHr0H5p3x3OTwAAAAAANY41Du2XPnWFVJyXenqldz0orViXdqkAZFjcNY157TMJoDNlITYFlcGtaSyWJwloteYxC+cLZBU1jtVe2Ockjbbo/HxhX9olAgAAAIDUUeNYbeVFTk2jW+O48qK0SwSgSyTVZxIAWpGF2BRUBrdmMa4+jlk4XyCrSByrrVjnNE99YZ+TNNJMFQAAAABkrLWhNx4cHLQTExMJFgdA3hhjDlhrB9MuR5yIdQC8iHUAuoVfvKOPIwAAAAAgEIkjAAAAACAQiSMAAAAAIBCJIwAAAAAgEIkjAAAAACAQiSMAAAAAIBCJIwAAAAAgUFPzOBpjfiTpO8kVB0AO/ay19hVpFyJOxDoAdRDrAHSLuvGuqcQRAAAAANB9aKoKAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETiCAAAAAAIROIIAAAAAAhE4ggAAAAACETimBPGmH9qcvu1xpj/6nltpTHmnvL/f7vq9b3GmEWxFDR8+TYbY3z//owx9xhjXu3zvv8Ww/Grz7+pzxZA8oh5ofb5V3Ve21v+ucEYc27VsVuOmwDCMcacYYz5jQbb1I1xccSncjx8ffn/G4wxf9rK/iIcf6Ux5uIG68ea3OdlxpjLPa9tMMbcWv4/93VtQOLYoay1k9bavwnY5LcD1rXDZqX795f2+QOIUTfGPGvt7wWs3iDp3DiPByC0MyQFJo4JWyvp9Skef6Uk38QxCmvtbmvtQwGbpB3juwKJY0KMMb9ojHncGLPHfQpujPnD8pOkR8tPW1YaY75mjHnQGPMNY8w55e0+Y4z5ijHmS8aY0wKO0WeM+Uz5//9kjLnKGHOOMWa0+gmTMeaPjTH7JH2gvHyFpPPLZXlLeXe3G2OeqPPE/hPGmFXl//+eMeYdxpibyuXd4z7Rqtr+G+Un5xPGmE3l1y4sH+trxpgtxph1coLal40x15Vf21t+z1ub+IzrfZ77jDGfM8YcMMacXd7ubmPMI8aYTxpjbjXG/E7V+Z8vaZEx5n8aYyaNMZeFPT6AU4h5ycQ8Y8ynjTGnG2P+b2PM35df22WM6THlp+rGmAuMMd8sfzb9xpheOYnqHcaYO8q7epsx5h/K/0zQMQHUV44zXzLGfLEc15aXX6+JdZJ+R9Jbyq+9ImyM8xzrFeVYuccYM1p+7VZjzL3le5r/VX7t58qx9wFjzJerjn+LMWZneXdvMMZ8oRyTllUd4yxjzKfL/+8pl3d5+eceY8xfesq0uXych8s/e43jzvK5P2SM6S8f/7pyeRaXf37VOPdnPQHn/Fo3ZhljDhtjXmeM2WiM2WaqWk4Y537uEUnuMvd1bULimJy3SXqftXajpE8aY1ZLOstau0HSTSrf0EhaLuep1Lslva/82mZr7ZslfUbSkN8BrLWzkvqMMUskHZG0XtIvSfq6u40x5pWS1llrL5L0lfL7HpT0tLV2g7X2H8ubjkl6k6R3eQ7zWUlvL///VyU9JOlKSRvL5/akZ/tXSPpDSW+uOsc/lnRFef/XSpos//sVa+19ksbLn8uvSPp9v/OtFvB5LpN0taQ/l/SbxpgLJR231l4i6dny+X+i6vyflvM7+KCkyyXdEOb4ABYg5iUT8x6X9EZJF0g6boxZLKlkrS1WbfOHkn5dzhP3s62185LukfRea+17y9scttb+qqQXJa1ucEwA/oy19m2S7pL0Oz6x7hOS/rEcc36kkDHO4/2SPlKOO7PGmPXl158s39O8yhhzhpwY8m45cfWny9t8QtJ2a+215eV5a+2vSfoHOXFHkmStfVHOw6alki6S9FVJr5O0t3zcd9cp1w+ttZfKibu/IWmTpO9aay+W9NeSfrd8/Pustb8i6aSkTdbaX5Y0peCayGckrSonv/8i6Re1MMavk1QsfwbPlM+D+7o2IXFMzp2S3mGcNtwXSBqQtME4/U/ulOQ+cXraWntSzk3Fq8tPYrYbY74q6f+R9DMNjvO8nETpH+QEjF+U9LWq9T8r6any/w8E7OefrbXHJZU8rz8qaaMx5qclzVlr/z9JfyTpTmPMJ3QqSLn+zVr73fJ27o3NGkkPStoj6b/IudGqdmn5c3lQ0oqAMlbz+zyfsdaW5NwcnSHpHJ06/0mfff3IWvvDcgA9I+TxAdQi5iUT874m5xx/onxeQ1qYvJ5RLsOcpG/5nW/5J3EOaI37/ZuU9Gr5xzpJTk2emotxrlWSbivv91eq3ud+l78n6XSV73PKD5P+2bsTz3vqff8flvPg7zflPDj7qqRCubZyuM6+vOe/StI15XJ+UE7SVu1lkv7GGPMVOQ/lfM/fWmslHZeTXP61nJYab5A0UbXZuVVl8Ivx3NclhMQxOTPW2q2Stkn6kJyL+ZfKT0M2SLq+vN0vlIPKGknPyfmSvKz8ZGaHpEZNir4u52nT1+R82Qastc9Xrf+OpPPL/39d1evWsx/vsvOic4P3vKRbJH2+/PKktXazpL1ymkNVW26MOdsY85OS3OYIT0q6vHzeryt/kU9Urf+AnKB1pRbexPnx+zyrz8OUy+6ef/VTduvzf5pwAdEQ85KJeU9KequkH8g5599X1dP3spfKZXiZpP+r/Fr18bznS5wDoltT9fM51Y911d+/tWouxrmelXRzeb+Dkh4ov173PqccV19bfr2Z77/byuK11tqnJPVYa/+wXFv5Xi3kPf9nJd1bLuebJP13z/EvlfStco3r5+oc3+uAnAT7q5J6JS2x1h6rWv98VRn8YjzxLiFtHVWuy9xgnBG1lkm63Vo7aYz5fvmJjJX0d5K+JOmHkv5ezhPpa+XcHLzaGLNb0iE5T4eCfE3SX8l5mjQh6eXVK621/2qc/n77JB2sWrXfOP1l7lBjn5PTvOKV5eX/YZy+SUskbfFs+2NJt8oJlH9cfu2PJH3BGGPkNC/7TTnNv/6+3EZ/l5wAsV/Sv4cojwI+T+92jxtjftcY82U5T+emy6sOGWM+J+fpGIDWEfMSiHnW2hPGmPnyee+XU7vxDc9mfyKn9vJbkr5bfm2vpI+Um+t/VwDicqIcr5ZK+k1r7b/ViXV/I+eh0mcl3azmYpzrzyR9whhzupwHTH4jI39U0k45sXVGTtL2DUn3GGN+QU4882Wt/W45vu0tv7TOGPNnkhZLeqTOW37KGPMlScfktP6Yl/SXxphHy+s/LqebwEeMMeNyks8PGmMGJb0k6X83OO+vSbraWvuSMeawnBhbXd7HjTE3lu/rvqNT8Y37ujYwTq0w0lBuw/2n1tp6TQFyyRjzT+UnTplhjFlkrT1pjHmfnHb4f5d2mYBuRMwDkGfGmA2SLrHW/kHKRamousfpkZN0vancciKJY22WtMha+7+S2D+yjxrHHDHGvFvSVVUvfd5a+xdplSdpxpjXyOl87vrPcof0Zv1N+WnaS3KejgHIAWJe5JgHIAdiinHnllsyvEzS3ySVNCbBGPMROYOcue601o6nVR40Ro0jAAAAACAQg+MAAAAAAAKROAIAAAAAAjXVx/HlL3+5XblyZUJFAZBHBw4c+LG11jtPXa4R6wB4EesAdAu/eNdU4rhy5UpNTEw03hBA1zDGfCftMsSNWAfAi1gHoFv4xTuaqgIAAAAAApE4AgAAAAACkTgCAAAAAAKROAIAAAAAApE4AgAAAAACkTi2yFobuAwA6FylUilwOSlcewAgWc3GWe967/WgE+I0iWMLRidHNfLESOUPwVqrkSdGNDo5mnLJAABJ27J7i4Z2DVVuDkqlkoZ2DWnL7i2JHpdrDwAkq9k4691+x5M7NLRrSDue3BHq/XlB4hiRtVaz87Mamxqr/KGMPDGisakxzc7PdsRTBQBAfaVSSXPzc5qema4kj0O7hjQ9M625+bnEah659gBAspqNs97tS6WS9h7aq+mZae09tFelUqlj4rRppvCDg4OWiWJPqf5Dcg2vGta2C7bJGJNiyYD2McYcsNYOpl2OOBHrEEZ1suga6B/Q+KZxFQrJPZfl2pMOYh3QPZqNs/W2H+gfqLk+5ClO+8U7ahxbYIzRtgu21byWlz8IAEBrCoWCxjeN17yWdNIoce0BgKQ1G2frbe+9PnRCnCZxbIH7dKFadftmAEDncmscq1X3eUwK1x4ASFazcbbe9t7rQyfEaRLHiKqrpIdXDeup65/S8KrhmvbQAIDOVN1MdaB/QAevO1hplpRk8si1BwCS1Wyc9W5ffT1wrw+dEqcXpV2AvDLGqK+3r6a9sltF3dfbl/uqaACAv0KhoGW9y2r6NI5vGtfQriEt612WWHNVrj0AkKxm42y97Tes2CBJ2rBigwqFQsfEaQbHaZG1tuYPwLuc9v7QGn4fjTFgBLpZqVSqSRK9y0khNrUfsQ7oLs3GWe967/UgT3GawXESUu+pQ1TMzZUt/D4ANOJNEtuRNErxXnsAAAs1G2e9673Xg06I0ySOGcHcXNnC7wNIVr0+IhwXABBW3HHV2zc96YHO8og+jhlR3X56bGqsMg9MnuZ86ST8PoDkjE6OanZ+tvJdch/M9PX2aevarRwXABAo7ri6ZfcWzc3PVfqsuwOgLetdprsvuzuBM8gnahwzJIm5uXjKHR1zpQHxS6s2v9uOCwCdKu64WiqVNDc/VzMqtjtq9tz8HDWPVahxzBC/OWOiJis85W5N3L8PAOnV5nfbcQGgU8UdV6tHxZ6emdaa+9ZIUs2o2XDwSWRE3HNz8ZS7NcyVBiQnrdr8bjsuAHSquOOqmzxWI2lciE8jI/zmjBleNRxpzpfq949NjWn1vasrSRA3LI3F/fsAcIpfbX7SD2S67bgA0Knijqtu89RqbrNVnELimCFb126tSercZCVqs1Kecrcm7t8HgPRq87vtuADQqeKOq9V9Ggf6B3TwuoMa6B+o6fMIB30cMybOubnoo9c65koD4uVXmy8p0dr8bjsuAHSquONqoVDQst5lNX0a3T6Py3qX0Vy1imkmKx8cHLQTExMJFgdx8T6N2XbBtgXL3LAgDsaYA9bawbTLESdiXfKstTUxyLvMcZE1xDogW+KOq6VSqSZJ9C53E794R41jh+Ipdzy42QMccX8X4q7Nj/uCXywW1dPT47sMAMgW73Wp0XXBu733muG9LjW6Dja73A5xl6E70+guQR+91oxOjta0lXdrcUcnR1MuGdBeWf8ubNm9paYfittfZcvuLTXbhT2Pt372rdp4/0YVi0VJTtK48f6Neutn3xqpfFn//AAgb7xxdceTOzS0a0g7ntwRarlRHG4Ut1td3w5JlIHEscPRRy8apjMBHFn/LoSduDnseRSLRR07eUwzx2cqyePG+zdq5viMjp08Vkkmw8r65wcAeeONq6VSSXsP7dX0zLT2HtqrYrEYuFwqlQLjcKO4XSqVWlrfjrif1LWHPo6Aj+ovmYv+oQvR76fzZf27UJ0suupN3Bz2PKqTRVf/kn7tuXpPpOaqWf/8EA6xDsiOenHVHQk17HJQHG4Ut1td3w6tlMEv3pE45lQW2k13A2utVt+7urL81PVP8Tl7cDPVHbL+XSiVSlpz35rK8sHrDtbt4xj2PIrFotaOra0sTw5PttTHMeufHxoj1gHZ4o2rB687uOA6ELTcKA43itutrm+HqGXwi3c0Vc2hLLSb7gZM2g04sv5dCDtxc9jzcGscq1X3eWxW1j8/AMibenG13nUgaDkoDjeK262ub4ckykDimDP0l2kPJu0GHFn/LoSduDnseVQ3U+1f0q/J4Un1L+mv6fPYjKx/fgCQN964Wh33B/oHNDk8Gbh88LqDgXG4Udyu7iMZZX27+jgmUQam48iZ6mk1xqbGKu2W6S8TL6YzARxZ/y6Enbg57Hn09PRo6aKl6tepPo17rt6jjfdv1NJFS5turpr1zw8A8qZeXN2wYoMkacOKDerp6QlcLhQKgXG4UdwuFAotrW9H3E/q2kMfx5zKQrvpbkBf0sbo99Mdsv5dCDuPY9jziHsex6x/fmiMWAdkS7PzNjaax7HR/rtpHkf6OHaQLLSb7hZMZwI4sv5d8CaJ9ZJGKfx5eJPEVpLGZo4LAAjHG0cbXQe8yyFGFk10uR3iLgOJY87QXwZAJ6jXpyRL++s2fH4Aul2jOJi1OJlGeUgcc8avzfLwqmH6ywDIhbhHhmak6dbw+QHodo3iYNbiZFrlIXHMmDBPD7au3VozEI6bPG5duzXS/jpJt50vkDdxjwzNSNOt4fMD0O0axcFSqZSpOJlm3GZwnAwZnRzV7PxsJSl0/xD6evvqJoXt3l/Wddv5ZgUDRqBZ1Rc5VysjQ8e9v27D5xcOsQ7oXI3iYNbiZNLlYXCcjOMpfGu67XyBPKseFtzVysUu7v11Gz4/AN2uURzMWpxMqzwkjhlR3VdxbGpMq+9dXRkAJ8ofQtz7y7puO18gz+IeGZqRplvD5weg2zWKg1mLk2mVh8QxQ/LwFD5sH8I0+hpm7WkQgIXiHhmakaZbw+cHoNs1ioOlUilTcTLNuL0osT2jaX5PD1rt9xPX/sL2IUyrr2Hc5wsgfn4jQ0uKNDJ03PvrNnx+ALpdozhYKBQyFSfTjNskjhnhfXqw7YJtNZ1em01+ktif24fQfX/1/q21lSQxzHZxi/t8ASRn69qtNbHAvehF/Y7Gvb9uw+cHoNs1ioNZi5NplYfEMSOy/hS++v1jU2OVhMzbhzDsdnHjqTnQ3Uqlknp6enyXXd6HV60+zIp7f2nxljmP5wAAQbzxuVQqqVAo+K5vNp4nHf8b7b8dcZvpODIm7psQ75fCuxxlf2vuW1NZPnjdwbr7s9Zq9b2rK8tPXf9UW/6gO+UmLk8Yoh7Nirs5+1s/+1YdO3lMe67eo56eHhWLRW28f6OWLlqqL739S4kdlymAuguxDsgvb7ze8eQO7T20VxtWbNBNr7up4bI3vrc7/rf7eEzHkRNxPvUdnRzV9ontNSNCbZ/YrtHJ0Uj72/HkDg3tGqp5bWjXkHY8uaPmtTRHnuKpOZBtcU+dUywWdezkMc0cn9HG+zdWksaZ4zM6dvKYisViIsdlCiAAyAdvvC6VStp7aK+mZ6a199BeFYvFwOXqwXFm52dVKpXaGv+zdL2hqWqHiruvYfWXbKB/QOObxjW0a0jTM9OSpBvX3KhCoUBfQwCB4m7O3tPToz1X76kki2vH1kqS+pf0V2ogkzhuWs3yAQDN8YvXA/0Dmp6Zrlw3/Jbdlnb1ukO1I/5n6XpDU1UfndDk0Vqr2x6/TX/77N9WXnvna96p91/4/kjn4lbbu8mi5Hyp3Gp8F823ugvNtxBF3M3Zi8Vi5WIvSZPDk759HOM8blrN8tF+xDog37zx+uB1Bxd0vwpa9sb3dsf/dh6PpqpNGJ0crTvpZ9Qmnmn57Yd/Wwd+eKDmtQM/PKDffvi3I+3vptfdpPFN4zWvjW8ar0kaJWekp3oD5pA0ApDib87uNk+t5jZbTfK4WZsQGgBQX714Xa/7VdByvdzAb33csnK9IXH0yFI74la47a+fnXm25vVnZ56ttM9ulttHslp1H8pq9DUEUE/cExdX92nsX9KvyeFJ9S/pr+nzmMRx05yAGQAQnjdeH7zuYKUZ6kD/gCaHJwOXD153sCa+V/d5bEf8z9L1hj6OHllqR9wKY4ze8NNvWJA4StIbfvoNTZ8HfRcBxCHuqXN6enq0dNFS9etUn0a3z+PSRUtr+jhmecojAEAy6sXrDSs2SJI2rNignp6ewOVCoVAT3wuFQlvjf5auN/Rx9NEJ/VZGJ0f10rGXFvRxPH3p6ZGHnj86f1Tvu+B9lb6Ltz9xu07rPW3B/uKeBgTZRb8fRBF3P/JisVjTp9G7nNRxO6E/PMIh1gH51mgex0bLjeJ9u+dxTPJ49HFsQlbaEbfqd1f/bt0+jr+7+nej79T7EdT5SLbs3qKhXUOV5rClUklDu4a0ZfeW6McFkAhvXGtXnIv7uN4HU34PqsI2ow9bvk5plp/W3wEA+PHGIW83q0bL3vd743Oj64Z3uVG8bzX+N4rDjfbfjrhN4uiRpXbErXCTtWdnnq20zx7oH9CzM8/WJHVhuX0/d07vrOn7uXN6Z03fz1KppLn5OU3PTFeO407bMTc/F6lvJYBkpDUQWNwPl+I+j04ZIC2sbjtfANnnjUvuXOLu3OGNlvMWx5qNw2nFbRJHD792xMOrhnPVb6VQKGhZ77LKnIuFQkHjm8Y10D+gZb3Lmm42Wv05jE2NafW9q2v6O7qfS/Vx3Llvqud+pLkqkA1pDQQW98OluM+jUwZIC6vbzhdA9nnjUvVc4nsP7VWxWAxcrh68Jg9xrNk4nGbcpo+jj7DtiONubxy2b2DY48a9v7B9P0ul0oK5cFo5LrKLfj/5VX2xcbVjILDqZNHVysOluM8jrc8lLd12vlER64D2qReX3EqJsMt5imPNxuGk4zZ9HJsUpt1y3NXEYZtvNXPcMP1+wu4vbN9Pt9zV6jWPpXkUkK7qkdlc7bjIui0TqrXSIiHu80jrc0lLt50vgOyrF5fqXTeClvMUx5qNw6ldvxPdeweLu5o4bPOttJplhe37WV3u6r6V1eeVxHkAaF5aA4GFfbgUVtzn0SkDpIXVbecLIPvqxaV6142g5TzFsWbjcFpxm8QxorB9/sIK2zcw7uOG3V/Yvp9h+1bGfR4AmpPWQGBhHy6ldR6dMkBaWN12vgCyzxuXqq8TA/0DmhyeDFw+eN3BXMWxZuNwmnF7UWJ77gJu8lPdvriVpMdNsqr7BtZrvtXMccP0cTTG6JbBW2r2d8vgLQv2t3Xt1po+iG45vNvdfdndNcdxz6uV8wAQr7QmFPZ7uDS0ayjywF1xnkeWJlpuh247XwDZVy8ubVixQZK0YcUG9fT0BC4XCoVcxbFm43CacZvBcVoQd8fUsANGhD3ult1bNDc/V3m/u/9lvct092V3V7bb8eSOymhU1cfdsGKDbnrdTU2fR1gMyNAZGDAi39IaoCrswF1hxX0e3TZwV7edbxTEOqC9vHGo0XXDu5y3ONZsHE4ybjM4TsziriZupm9g2L6GYfpMVg9x7D2uO6RxEmgeBWRDWhPYhxm4qxlxn0dan0tauu18AWSfNw41um7Ua9mWJ83G4TTiNk1VI4q7mjhs862wx61+v9tnUlpYg1koFCrV+97t3Or+JNA8CsiGuJ9YFotF9fT0+C4ndVwAQGfzXie815dGNY7tvs6kffwk0FS1RXmYxzHMfIrFYlFrx9ZWlieHJ+ve7MUt7uZqaD+ab+XX6OSoZudnKw9v3JYAfb192rp2a9P7e+tn36pjJ49pz9V71NPTo2KxqI33b9TSRUv1pbd/KbHjAu1ArAPS471ubP7iZn37pW9r6DVDuul1Ny3ojpX2dSbt47eKpqoJibuaOGzzrTDHDTvk/Y4nd+iah66pee2ah67Rjid3hC53FKOTo9o+sb1myo/tE9uZxxFog7inxCkWizp28phmjs9o4/0bK0njzPEZHTt5TMViMZHjAgA6m/e6USwW9e2Xvq2Z4zMaf3ZcxWKxpjtWsVhM9TrTydc5mqp2KG+fyepmq0O7hmoGzKnu41i9nSTduObGRGoAq79UkjOaanWfx06ozgeyrLp5+NjUWOW7GHWAqp6eHu25ek8lWXRbMPQv6a/UQCZxXABAZ/O7bvQv6a+53lR3x0rzOtPJ1zlqHNuk3hwsSQo7n6Lbx7He/JH1+jjGdR7M4wikr/ri5mrl++cmj9Wqk8akjgsA6Gz1rhve6029ec+rtfM6k/bxk0Li2Aajk6M1I4W6VdZJN8m8+7K7FwyEM75pvGYqDkm66XU3aXzTeM1r45vGF0zFEfd5dOqXCsgL9ztcrZVRjd3mqdXcZqtJHhcA0NnqXTe815t6sxBUa+d1Ju3jJ4XEMWFpt3MO02fS7VtYrbrvobtN3OfRqV8qIA/inhKnuk9j/5J+TQ5PVpoRVSePTMUDAGiG97pRfX1xrzfVU9gVi8VUrzOdfJ2jj2PCst7O2fvHXd3XUDpVAxj3eYQ9LoBkxD0lTk9Pj5YuWqp+nerT6PZ5XLpoaU0fR6biAQCEVe+6ce7p51ZGVe3p6amZwq6npyfV60wnX+eYjqNNrLVafe/qyvJT1z/Vlj+cMNNdNDNkcJznkfehiuFgiPp8Yx5HIBxiHZAu5nFsH794R41jG/g1yUy6Vm3L7i2am5+rGUG1eo4b19a1W2v+mN0nI96yxX0eYY8LID/CTikUVti5Xk+ePKlFixb5LrvCXsjzfMEHgDzyxndvHPfGYe+1oNFUdd5l7/G8iWij60Cz14l699V5u87QxzFhabVzLpVKmpufq7T3rp6eY25+bsFcjo2+XEmdR9zzYAIIL+4Br8LuL+x2W3ZvqRnswI1jW3Zvqdlu/d+u1xs//UadPHlSknOz8cZPv1Hr/3Z9ouUDAMTDG+/f9Q/v0hs//UZt/uJmSQvjf6tx2nu8v/7mX2vj/Rsrx/Pur9Hxmi1PXq8zJI4J82vnPLxqONF2ztXTb3in2ageaTXr5wEgGXEPeBV2f2G3C/vw6+TJkzpROqHjxeOV5PGNn36jjheP60TpRCWZjFS+R2+W/epHNfLozR0xcTMAZFFNvP/8Jp3cc7v+5d+e1vHicf3zv/2zTp48WRP/i8ViS9cv7/WlWCzqM9/6jGaOz+jbL327ZnCd2flZlUqlwOM1Wl9vKrs0B85sBX0c2yRsv5+wzbKaOa47MaokTQ5PttTfKO7yIf/o95Nf1RcrVysDd4XdX9jtqpNFV72HX9XJomtJzxJ945pvLGjmFLp8j96sscOPnNru7Eu07eI/5yFZFyPWAckplUoa+vwmTc8dqry2pLBYx0snKsvV8b/V61e964s7Umu9/TU6XrPlifv6Gze/eMcdfxts2b1F1zx0TU1zq2seumZBc6uwzbLC2vHkjrpzqu14ckfNa80036qepsOdxiPr1eoA6ot7LtWw+wu7ndtyolq9FhOLFi3SN675Rs1r3qSx6fItPqt2u8VnZeJiDgCdqFAoaPzltfes3zh7qGa5Ov63ev2qd33Zc/Ue3/01Ol6z5cnrXOYkjgnzVr+XvrLdeaLiaW7VbJ/ERorFosafHa87p9r4s+M1c6rF2bwMQH7EPZdq2P2F3c6Ng9WqH6653BrHatV9HiOV78SLtdudeJE4BwAJKZVKGvpxbeL2xsO1iV11/G/1+lXv+uKtbKlXqRJ1vVfc1992IXFMWKWv4bIVmp47pDUv3KvpuUMaWLai5slJ3H0Se3p6dO7p51aSxbVjaytJ5Lmnn1szp5rbV3Fsakyr711dM7ei90lKo+0A5EPcA16F3V/Y7aofng30D+jgdQdrJniu7uPoNlNd0rNET177pJb0LKnp8xipfIcf0fDZl+ipc96l4bMv0djhR3JxUQeAvKnE+/L98ZOvGq40U3XjenX8r+6DGOX65b2+VFeuuJUt1fsrlUqBx2u03u/habsHzoxDLqbjSGO42jj78rnV72vm7q28Nv7yjXWHrR/fNK419605tV2EpNF1z9vuWdDH0Z2Yu5qbFFa3sw5qXtZoOwDZF/cExWH3F3a7QqGgZb3Lah6eVU/w7MbFRYsWaXFhsaRTzVO/cc039MZPv1GLC4srzVVbKp+1UnmOWeIdAMSrXrx/7T88o3858i/6hZ/6BS1atKgm/vf09LR0/ap3vHf8/Dv0mW99plK5Ur2/QqEQeLxG6+vdT8d5/W2nzA+Ok8Yk8WHnPwyrXoffgWUrNH7VrgXJaZiBIMKKe6CKrHfkRToYMCLf4n4wF/c8iczjiKwg1gHJajSPo3d9q3E66XkcG5Uny9eZXA6Ok0a/urj7Gnqr3w+uvL7SbLXeQDiNmmWFVVMNXt3cKmKzsTxXqwNon7Bzs4bdrl7LjHq8SWK9pDGJ8gEAFqrXPLORegOfBa1vNU5791evRV6cy155vM5kuqlqddXt2NRYpaYryVqu6uZQbl9DKXrNX93mVqX3LmhuFbZZVliVavCzL9G2x/5OpjivbT290vrfitRsLM/V6gDqS6NFBwCgs3Ft6VyZb6oqOU8pVt+7urL81PVPtaWPY3Vfw4PXHWx5PsUw8ziG3S6s0le2q7D3I5ItSqZHpQ0fUOHNtyzYjuZbiIrmW/nkbUWw7YJtC5Zz990+tF96YZ+08iJpxbq0S4MOQ6wDGkv82kKcbwu/eJfpGkfJf7jaJG9q/IaAj9rXsN6Tl48e+OiCJy9ht2vquCe/p209vTLFedmeXm0/+T31TY4u2B/Nt4DukkaLjkQd2i996gqpOC/19ErvepCbCgBos0SvLcT51GW+j2O7+9XV9DWs7pPYQl/DNOZJrOzv8CMaWf9bshv/u0bW/5bGDj/iv79D+6V9dzg/AXS8vE5AXNcL+5ybCVt0fr6wL+0SAUBXSuzaQpxPXaZrHNPoV1fpa7hshcanvqlC8Rsa7+nV0KrXR+5rGObJi7udtbZmu2sHro30ZavZ3/ROueOg+u6PpzhA10mjRUdiVl7kxC43hq28KO0SAUBXSuzaQpxPXaZrHCVp69qtdROsJDvX3n3Z3c48i+WnGoXivMZfvjHSVBxS+Ccvdx68U/J+n0z59Qia2h9PcYCu0nEjJa9Y5zzwuviDPPgCgJQkem0hzqcu84mjlE6/usK5b3aeZpgeqafXWY7I78lL9ZfHWquj80e1c2pnzXY7p3bq6PzRSE1Vm9qf+xSnfL6BT3Fo0grknl+LjuFVw/kdKXnFOumi93IzAQApSfzaQpxPVaabqqbKfarR4shNQaNLSZ6aR7/cMOrDmWb2F/Z8adIKdIyta7fWjIzsXuBzmTQCADKBa0vnInEMsmJdy0lRM/MknrbkNF3bN6Cds9OV91/bN6DTlpwWqY/jaUtO07UD12rn9Klax2sHrvXfX5jzrdeklcQRyC1GSgYAxI1rS2cicWyDsE9eblxzo27/t/8tVSWOOv1s3bjmxkjHvXHNjbr9idtrXzSKvD9JdEwGkEnMMQsASBLXmZz0cewEjZ68uE1adx5+RMPLX6+nzM9pePnrtfPwI/6diQP6Glb2N7WzpnPyzqmdkfZXsWKddNlt0rlvdn4G1TbSFxJAG4xOjtbENTf+jU6OplwyAEAn4DrjoMYxIypNWs++RNse+zuZ4ry2fbdXWv9b9TsTN+hr2PRUJmH7Lh7aL+1+v7Pddx6TzjzPfzv6QgLd6dD+lvuHh1U9B66kmn7kw6uG2/NEOOz5tvFzAYDUhYl5rcbFNsTVTFxnMoLEMUO2rt0q+9WPypT7EJrivLYtPkum3tQjIfoaNtU5OWzfxbi3A9BZ2vzQKOxcuYlp5qEbD9MAdIswMa/VuNimuJr6dSZDaKqaMeacX66ZFsOc88v1Nww5fUbozslhp+OIezsAnSWFOWHDzpWbiLDny1y5ALpJmJjXalxsY1xN9TqTIdQ4Zo3bh3DqAWnVlf5PTsJuJ4Wrxg87HUfc2wHoLCkMoOU3V25bLuphz5eBxQB0kzAxr9W42Ma4mup1JkNIHLOmmT6Ecfc1DDv9SNzbAegcbX5o1NRcuUngYRoALBQm5rUaF9sUV1O/zmQIiaOP1Ibcpa8hgLxr40OjpgcCSwIP0wBgoTAxr9W42Ia4monrTEaQONYxOjmq2fnZyh+H+6Shr7dPW+sNVBOnuJs90TwKQIdraiAwAACaxHXGkZ/Bcdo0J2D1kLvufC1udfTs/Gz9+Q/jFHaexGa2u/AGqf9nnZ9xPJWJ+3fBfI+AJC2IL4nHmxTFfa6hBwIDAOSS9zpRKpUC18eN60xeahzbOIx56kPuxt3HceIe6Wsfd/7/tY9L/edIg5tbK1+cvwuGqAckpdzSoc266VwBAK3zXjd2PLlDew/t1YYVG3TT627iOtIm+ahxbPMw5h01tPvUA8HLSZUvrf0BOVTT0uHRm2W/+lGNPHpz+1o6tLHWP9K5hi3fP/6R9Jevc34GmbhHuu8q52cQWkMAwCnNxsR7r5L+9Eznp98+Gu1z4h7Ze39ds4cer7QGLJVK2ntor6ZnprX30F6VSqX2tg7sYvmocWxzP72OGtp91ZXSc4/WLrejfGntD8ihysOq2e9r7PAjGiu/Pnz2JcnHnTbX+jd9rmHL949/VNu6QpLe8qGF203cI+16t/N/NzbWa4VBawgAOKXZmHjvVdK3yzH22486yxs/ULuPy2471Xqu3j7L8dpI2iZJb/j1mtaAA/0Dmp6Z1pr71khqY+vALpaPGkd3uN2LPxj8hxrD02HvkLtPXf+UhlcN1/R5TOK4FWHPNex2g5ulX3qPtPxc52dQM9Uw5xH2uGHFvT8gp4wx2rb4rJrXti0+K/kLYAq1/k2da+jWFQ8GL1deD9kKg9YQAHBKszHxu19fuOzdx9QDwfusis9G0raZl2pWj28ar1kmaUxePmocpcbD7cb0dLjpIXeTeCod59Duh/ZLj9/llO/xu6SBy9s332NYDFEPOA+tTrxY89rIiRe1LempgFKo9W/qXEO3rrjiVE2ju1x3u5CtMGgNAQCnNBsTX/WLp2oc3WXvPlZd6YzT4bfPqnhtJY30ny4dObV6aNdQzeZtax3YxfKTODYS43yFTQ25m/V5EpnvEci8SkuHw484TTYXn6WREy9q7PAjUtIXwjZPTN/0uYYtn9ssdepBJ2ms10xVOtXqYuoB56bErxVGmz8XAMi0ZmPi9Z93mqd+9+tO0nj9553Xvfs48zz/fZbjs33m7zXSf7rGjnxTw6uGdcvgLRraNaTpmWkN9A9ofNO4tk9srzRhJXlMTuckjjE/HQ495G6aT6Un7ml888N8j0Dm1W3pYK1UHiEu8QtgG2v9I51r2PK95UP+CWO1wc3hRpemNQQAnNJsTHSTxaB9NNrn4GaZwc3qmxzV8JnnVa4bG1ZskCRtWLFBhUIhuHUgYmOaGXlocHDQTkxMJFicFh3an87T4TSOWz3AgyRt+gv/G6Gw5Uvr80OuGWMOWGsH0y5HnNKKddbTVNO73Em66VzRGYh1QLq814lSqaRCoeC7HtH5xbvOqXGU0ns6nMZx6w3wENTkKq4+kwASk+XJheNO9LJ8rgCA7PFeJ6qTxnrrm8UDzcbyMaoqFvIO6NDqNBsA4GN0crRmVGm3n+Lo5GjKJQMAoHVc58IhcWynOKftaGaajbCTXQOAh7VWs/OzNVMSNZxoOWysi3u7sLEu7uMCQB7FHePCxGDvMb3vSSHuRrrOdanOaqqaZXFP2xF2mo2wk10DQB3VUxJVT7zsO9Fy2FgX93ZhY13cxwWAPIo7xoWJwd5jXnjDqWmUnntUmnn+1L1tG+Nu09e5LkaNY7vEPZl06EmxQ052DQA+qi+qrqamKKon7u3Cxrq4jwsAeRR3jAsTg73HnHrQ854HU4u7TV3nuhiJY7u4012Ynnimuwi7P/pCAmiR22ynWnVfkBphY1Pc24WNdXEfFwDyKO4YFyYGe4+56grPe65ILe42dZ3rYjRVbZcV66TLbjs172Kr02KEnYh1cLNT9e9Oik0zVQBNqO7r4TbbcZelOk9kw8amuLdzY1ujuW3jPi4A5FHcMS5MDK53zP5zat8zcHnb427T17ku1lnzOGZZWv1q6KeDhDG3WecbnRzV7Pxs5eLpXmT7evu0de3WtIsHtAWxDuhcXOdqdcc8jllWry15vQQu7HZxHxcAfGxdu7VmPiu3LwhPYAEAnYDrXDj0cWyXtPrV0E8HQAy8F08upgCATsJ1rrH81DiG6fcXZpu4jxl2u2b61YTtCxkG/XQAAAAAtCgfiWOYfnpp9Q1s5rgr1jUu06H90u73O/v7zmPSmefFkzySMAIAAACIKB9NVcPMNZPWPIlpHRdAd5u4R7rvKudnqw7tl/bd4fyMQ9j9/eMfSX/5OudnkHuvkv70TOdnHMcFgE7Uagz0xmTvdabRsvf49cpDnM61fNQ4uv303Fq9ev30wmwT9zHTPC6A7jVxj7Tr3c7/n3vU+Rl1qp20Wmv84x9JX/u483/351s+tHC7e6+Svl0+x28/6ixf//nkzwMA8qTVGOiNyf/61KnY+9yj0ne+Jj39Gf/lmeelx+86dfzLbjvVgs4tj0Sczrl8JI5h+unF3ZcvbF/DZo47cU98c4wB6F5TDyxcjpo4pjWS89SDC5frJY7f/XrwcrPHBYBO1GoM9MZkb6z9P/8YvDz1YO3xpx6o34KOOJ1r+WiqKjl/WBe9N/gPLMw2Ybl9Db/9FednUJV6mOO6NQTPPer8DGpeFud5AOg8q64MXm5GWiM5r7oieNn1ql8MXm72uADQiVqNgd4Y7I21r35L8PKqK2qPv+rKheUhTudePmoc0xD30+s4awgAdDc3djRqwRBGEq01wuzPrV2cetC54ahX2yg5zVLvvcp5+v2qX6zfTDWJ8wCAPGk1BtaLyd6Wcj/7S8HLA5fXHv/M8xaWhzida8ZaG3rjwcFBOzExkWBx2iTs1B5xtsOu7pMkSZv+gsQRHcEYc8BaO5h2OeLUMbEOQGyIdQC6hV+8674ax7AJYdxPr+OsIQAAAACANuq+xLGZJqhxz384uJmEEQAAAEDu5GdwnLjQMRcAAAAAmtJ9iaM7zca5b3Z+0jEXAMLxTvbsJ+wEz3FPBM3E0gAQnjdmNoqhra6P6z1ITfc1VXWn2SjOS995zBnxieQRAIJVD/D1XHlS6HpN78P2I497ALK49wcAncwbMy+77dT9cb0Y2ijGRonBxO3c6b4ax3p9HAEAwepNKVRP2BgbdywmtgNAeN6YOfVAcAxtFGOjxGDidu50X+JIH0cAaN6qK4OXXWFjbNyxmNgOAOF5Y+aqK4NjaKMYGyUGE7dzh3kc81wl3inngVxjbrMu4p0M2k/Y2BR3DCMmIkHEOnQcb8xsFENbXR+mDMgEv3jXnYljJ6BdODKCmykA3YBYB6Bb+MW77muq2iloFw4AAACgTUgc84p24QAAAADaJLnpOLqpzXIa57pindM8tVs+YwAAAACpSSZx7Kb+d2me64p1nfu5AohHmAdbYQe9AQBEl3alSrOD4QAeySSO9frfdeofZDedK4B8CfNga+Ieade7nf8/96jzk+QRAOKVdqWK9/iX3Sbtfn93VPIgNsn0ceym/nfddK4A8iXMIFpTDwQvAwBal/aght7jTz3AIItoWjI1jt3U/66bzhVAvrgPttwnyvUebK268lRNo7sMAIhXmHjczuOvulL6zmPplQe5lNzgON3U/66bzhVAfoR5sOU2S6WPIwAkJ+2KhnrHP/M8Kj7QlOQSRwBA+sI82BrcTMIIAElLu6LBe/y0y4PcYR5HAAAAAECgzkocD+2X9t3h/IxjOwAAAABABzVVDTvMcdrDIQMAAABAznROjWPYYY7THg4ZAAAAAHKmcxLHsPMpMu8igDjF3fQ97ib3E/dI913l/Mxa2QAA/hrF70brm43F3u2J5fDonKaqYYc5Tns4ZACdI+6m73E3uZ+4R9r1buf/7lyNUUdPpTsAALRPo/jdaH2zsdi7/WW3SbvfTyxHjc6pcZScP+iL3tv4DzvsdgAQJO6m73E3uZ96IHg5zbIBAPw1it+NlpuNxd7tpx4glmOBzkocAaCd4m76HneT+1VXBi+nWTYAgL9G8bvRcrOx2Lv9qiuJ5Vigc5qqAkC7xd30Pe4m926zpakHnJuAqM1UkygbAMBfo/jdaH2zsbje9meeRyxHDWOtDb3x4OCgnZiYSLA4APLGGHPAWjuYdjniRKwD4EWsA9At/OIdTVUBAAAAAIFIHAEAAAAAgUgcgzB/DQAAAAAwOI4v5iIDAAAAAEnUOPpjLjIAAAAAkETi6I+5yAAAAABAEk1V/TEXGQAAAABIInEMtmIdCSMAAACArkdTVQAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAAAEAgEkcAAAAAQCASRwAAAABAIBJHAAAyZOiuxzR012NpFwNoK/7ugewjcQQAAAAABFqUdgEAAIAqtS2PP3+kZnn8hvWplQlIGn/3QH5Q4wgAAAAACESNIwAAGeDWsFDjgm7C3z2QH9Q4AgAAAAACUeMIAECGUOOCbsTfPZB91DgCAAAAAAKROAIAAAAAApE4AgAAAAACkTgCANCCobseq4wICSAefK+A7CFxBAAAAAAEYlRVAAAicGtDHn/+SM0yo0MC0fG9ArKLGkekLuvNUbJePgAAACBp1DgCABCBWwNCjQgQH75XQHaROCI1WW+OkvXyAQAAAO1C4ggAQAt4mATEj+8VkD0kjkhN1pujZL18AAAAQLswOA4AAAAAIBA1jkhd1mvysl4+APlw/q0PS5KevvXSth43bKuJsNuldR5xoiVJ8hp9xj/3gYckSc995PK62zd6P79DoP2ocURiwk5jkfXpLjrlPAAAAICoqHEEACBBbg3d7LGTNctJ19iFHRk67HZpnUecGC07eY0+Y7emsWid7Ve+/6Ga93v/zvxqIvkdAu1H4ojYxX2zkpZOOQ8AAACgVSSOAAAkyK2Ra3cNXdi+YmG3S+s84sRo2clr9Bm7fRqj9nHkdwikh8SxC8Q9MEJcNyHeZitxlS8u7nHcm6RWzxcAAADIKxJHAADaIK0aurAPs8Jul8eaRi8e8CWv0Wfs1jT6bd/o/fwOgfYz1trQGw8ODtqJiYkEi4M4efveXXjOckmN++i1ul1Y3g7wfUud5xjem5K4jxtWWsfNG2PMAWvtYNrliBOxDoAXsQ5At/CLd0zHAQAAAAAIRI1jFwjb984dEvuF2y4P3C7uvnxhjxv3gAzejvntOm5YafSZjHJMnsKngz61C2X9MwlbvrRiTp4HvWkHYl1zvH9PjQbD8cr69xnoZNQ4AgAAAAAiocYRCybfdTWqAWyVdxLgHuP89NYAxt3XMK3jhpXGcVs5Jk/h24u+twtl/TMJW76w/b7jltZx84ZYF47376kR7/ch699noBtQ4wgAAAAAiIQaxxwL2/4/bF++uPs4xt23Mux5xP25pNXPIsxx4y4bfRwdeYh19P9ZKOufCX0c841Y1xz6OKLT/eAHP9CRI0fSLkYsFi9erJe//OU644wzJPnHO+ZxBAAAAIAmHDlyRD//8z+vnp6etIvSEmutjh07phdeeKGSOPqhxjGHwrb/D9uXL+7jxt2fJ+vzPaYhS+fKU3gA3YBYB6Da1NSUVq1a5bs+b7Xm1edDH0cAAAAAyJH3vOc9aRehoqNqHPOW2bcq7j6EYcXdNzBsv5q05pkMKy/zLsaNp/AAugGxDkA1vxrHqK3CRkdHdeLECUnS4cOHdcYZZ2jDhg360Ic+pHe+85265JJL9LGPfUz9/f36pV/6JU1NTenEiRN69atfrde+9rX6whe+oOnpaX34wx9u2OS00flQ4wgAAAAAGfSGN7xBJ06c0L//+7/rzDPP1M/8zM/oueee03nnnafNmzfr61//ut7+9rfrD/7gD/SFL3yhsv2Pf/xj/cd//IcKhYJ6e3v19NNPJ1bGjhgcx5vZZ6EWph3CjmrqXY76ubg1g26fyUY1hWGP06im0T2Od7nV48Ylzb+/Tv8bB6T4R0pOq5VD3CNIhz2PsNtlYZTmdu4PzWn0+Xv/zrx/780uM+oq8so7J2nYv9EjR47oJ37iJ/S1r31N559/vl72spdp/fr1+vGPf6y//uu/1q//+q/rYx/7mL785S/r137t1yrbT09P62Uve5mWLl2qYrGoYrGY2Ll1ROII5AkXOwAAAFR729veJkm66aabal5fu3Zt5f933HFHO4u0AH0cu0Dcn0vYp+Fxy/ocY3HPb5kX9PtBUuIeQTrsCM1uzYeXt6YwbPnC7i/u80hrROqs7y+qbo11jT5/799Z3LzHy8rfA9BoVNW8CdPHkRpHhOYGa/emptMSoKR1a5NqAAAA5F9H1TgiWTzla02nfn7d+hQe7UMfx/ro49he3R7r6OMI1KLGER0pruAatbMvHHx+AAAAXeLQfumFfdLKi6QV62Lf/YMPPqi3vOUt+omf+Anfbd7znvfo4x//eGzHpMaxC3TaU9+867TPr9ufwgPoDsQ6ANUCaxwP7Zc+dYVUnJd6eqV3PdgweXz/+9+vD33oQ7rnnnu0e/dubdy4USdPntTrX/96jY+P6+qrr9bDDz+sn/3Zn9X69ev1wAMP6D3veY/uuusuvexlL9Mv/MIvqFgs6utf/7peeukl3XLLLfrIRz6ij33sY3rf+96nFStWqKenR+edd15lfxdffHHd86HGsQsl1aeuUxKetPD5AQAAdLAX9jlJoy06P1/Y1zBxfPvb3677779fTz/9tKy1Ou200/Tcc89Jkt7ylrfo4osv1r/927/p+eef1+zsbOV93//+9/Wxj31MknTzzTfrz//8z/XYY4/pq1/9qiTpRz/6kfr7+/V7v/d7uvnmm3XeeedV9tesQtPvAAAAAADUt/Iip6bR9Dg/V17U8C2Dg4P67Gc/qze96U1avXq1/vM//1Ovfe1rJUmFgpOyvfTSS1q8eLGmpqYq73vlK1+pHTt26Ctf+Youv/xy/emf/qk+97nP6Zd/+ZclSa94xSs0MzOjv/qrv9KrX/3qmv01i6aqXaDTmkY20m3nmzaabyErwg4Ck9aUQqgvLzGbWFer2d+bd/uwg0UBWdVwcJyE+zjGjaaqAAAAANBuK9blImFsBoljF8j6U9y4ME8i0J28E5D71Ty6NY3uXLTUPKaLmJ1Pzf7evNu7NY0uah7Riay1Msb4LucVfRwBAAAAIAajk6MaeWJEbndAa61GnhjR6ORoyiVrHTWO6BjMkwh0J7dmsVEfR7dmkZrGbCBm51Ozvze/7alpRCey1mp2flZjU2OSpG0XbNPIEyMamxrT8Krh0DWP4+PjGhoaamr917/+da1YsUIrVqxo7SQCkDgCAAAAQIuMMdp2wTZJ0tjUWCWBHF41rG0XbAtMGqvncfzsZz+rM888szLf4p49e3TWWWdpfHxce/bs0WOPPaYzzzxTn/vc5/RTP/VTetOb3qTDhw/rJ3/yJ/XFL35R//Ef/6Fzzz1Xq1ev1he+8AVNT0/rwx/+sM4444yWzo/EER2Hp9ZAd2o0mqqLmsZsIWbnU7O/N+/21DSiU7nJo5s0SmqYNEqn5nGcmpqqTMPhzrc4Pj6uP/mTP9HXv/71mvdcfPHF2rBhg/7qr/5Kr3rVqyQ5o6O68zo+88wzKhQK6u3t1dNPP62LLmo8LUgQ+jgCAAAAQAzcPo3Vqvs8+nHncXzjG99Yec2db/EVr3iF7rrrLn3ve9+reY8xRsYYlUqlymurVq3SX/zFX2jXrl165plntHTpUhWLRRWLxVZPjRpHAAAAAGiVmzS6fRqr+zhKjWse//7v/16SdM0119S8fumll+qZZ57Rxo0bJUkf//jHa9bfeuutlf+vXbu25fPwQ+IIAAAAAC0yxqivt6+mT6Pb57Gvty/ylBwXXXRRy81M40DiCAAAAABNKhaL6unpqXlt69qtNaOnusljVudxtNbq2LFjobYlcQQAAACAJixfvlzf+ta30i5GLBYvXqxXvvKVDbcjcQQAAACAJpx55pk688wz0y5GWzGqKgAAAAAgkGk0NGzNxsb8SNJ3kisOgBz6WWvtK9IuRJyIdQDqINYB6BZ1411TiSMAAAAAoPvQVBUAAAAAEIjEEQAAAAAQiMQRAAAAABCIxBEAAAAAEIjEEQAAAAAQiMQRAAAAABCIxBEAAAAAEIjEEQAAAAAQiMQRAAAAABDo/wcRnzjMqxRMfQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "metrics = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "pairs = [(i,j) for i in range(4) for j in range(4) if i<j]\n",
    "marks = ['+', '.', 'x'] # markers for every class\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(16,10))\n",
    "\n",
    "f\n",
    "for row in range(2):\n",
    "    for col in range(3):\n",
    "        i, j = pairs[3*row + col]\n",
    "        ax[row][col].set_title(f'{metrics[i]} vs {metrics[j]}', fontsize=8)\n",
    "        ax[row][col].set_xticks([])\n",
    "        ax[row][col].set_yticks([])\n",
    "        \n",
    "        for mark, (species, points) in zip(marks, points_by_species.items()):\n",
    "            xs = [point[i] for point in points]\n",
    "            ys = [point[j] for point in points]\n",
    "            ax[row][col].scatter(xs, ys, marker=mark, label=species)\n",
    "            \n",
    "ax[-1][-1].legend(loc='lower right', prop={'size': 6})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = TypeVar('X')\n",
    "\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"split data into fractions[prob, 1-prob]\"\"\"\n",
    "    data = data[:] # make a shallow copy\n",
    "    random.shuffle(data)\n",
    "    cut = int(len(data) * prob)\n",
    "    return data[:cut], data[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "pct_correct 0.98\ndefaultdict(<class 'int'>,\n            {('setosa', 'setosa'): 21,\n             ('versicolor', 'versicolor'): 11,\n             ('virginica', 'versicolor'): 1,\n             ('virginica', 'virginica'): 12})\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "iris_train, iris_test = split_data(iris_data, 0.70)\n",
    "\n",
    "confusion_matrix: Dict[Tuple[str,str], int] = defaultdict(int)\n",
    "num_correct = 0\n",
    "\n",
    "for iris in iris_test:\n",
    "    predicted = knn_classify(5, iris_train, iris.point)\n",
    "    actual = iris.label\n",
    "    \n",
    "    if predicted == actual:\n",
    "        num_correct += 1\n",
    "        \n",
    "    confusion_matrix[(predicted, actual)] += 1\n",
    "    \n",
    "pct_correct = num_correct / len(iris_test)\n",
    "print(f'pct_correct {pct_correct:.2f}')\n",
    "pprint(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def random_point(dim: int) -> Vector:\n",
    "    return [random.random() for _ in range(dim)]\n",
    "\n",
    "def random_distances(dim: int, num_pairs: int) -> List[float]:\n",
    "    return [distance(random_point(dim), random_point(dim)) for _ in range(num_pairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Curse of Dimensionality:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ca2bd783c694d2281b66732583e231f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-28eb25b39194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Curse of Dimensionality\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mavg_distances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmin_distances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-dfab6c134e18>\u001b[0m in \u001b[0;36mrandom_distances\u001b[1;34m(dim, num_pairs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrandom_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_pairs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-dfab6c134e18>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrandom_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_pairs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-fa50199f3f79>\u001b[0m in \u001b[0;36mdistance\u001b[1;34m(v, w)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#alternative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mVector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mVector\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mVector\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ef520d57ff90>\u001b[0m in \u001b[0;36mmagnitude\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mVector\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m\"\"\"Returns the magnitude (or length) of v\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_of_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# math.sqrt is square root funtion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-7b80b9d240e6>\u001b[0m in \u001b[0;36msum_of_squares\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msum_of_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mVector\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Returns v_1 * v_1 + ... + v_n + v_n\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4d5128194034>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(v, w)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"vectos must be same length\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw_i\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4d5128194034>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"vectos must be same length\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw_i\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm_notebook\n",
    "\n",
    "dimensions = range(1,101)\n",
    "\n",
    "avg_distances = []\n",
    "min_distances = []\n",
    "\n",
    "for dim in tqdm_notebook.tqdm(dimensions, desc=\"Curse of Dimensionality\"):\n",
    "    distances = random_distances(dim, 10000)\n",
    "    avg_distances.append(sum(distances) / 10000)\n",
    "    min_distances.append(min(distances))\n",
    "    \n",
    "min_avg_ratio = [min_dist / avg_dist for min_dist, avg_dist in zip(min_distances, avg_distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "ax.plot(dimensions, avg_distances, label=\"avg_distances\")\n",
    "ax.plot(dimensions, min_distances, label=\"min_distances\")\n",
    "ax.plot(dimensions, min_avg_ratio, label=\"min/avg-ratio\")\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "ax.margins(x=0, y=0)\n",
    "ax.set_title('10,000 Random Distances', fontsize='xx-large')\n",
    "ax.set_xlabel('# of dimensions', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In low-dimensional datasets, the closest points tend to be much closer than average. But two points are close only if they're close in every extra dimension - even if just noise - is another opportunity for each point to be farther away from every other point. When you have a lot of dimensions, it's likely that the closest points aren't much closer than average, so two points being close doesn't mean very much (unless there's a lot of structure in your data that makes it behave as if it were much lower-dimensional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Spam/No Spam classification.\n",
    "\n",
    "$$posterior = \\frac{prior\\:x\\:likelihood}{evidence} = \\frac{S\\,p(X\\,|\\,S)}{p(X)} = \\frac{S\\,p(X\\,|\\,S)}{p(X\\,|\\,S)\\,p(S) + p(X\\,|\\,\\neg S)\\,p(\\neg S)}$$\n",
    "\n",
    "The numerator is the probability that a message is spam and contains bitcoin, while the denominator is just the probability that a message contains bitcoin. We can think of this calculation as simply representing the proportion of bitcoin messages that are spam. In practice we are often only interested in the numerator. P(x) is calculated using the law of total probability. For the spam example it is often assumed that a message is equally likely to be spam or not spam($P(S)=P(\\neg S)=0.5$) so the term can be reduced.\n",
    "\n",
    "The key to Naive Bayes is making the assumption that the presences (or absences) of each word are independent of one another, conditional on a message being spam or not. Intuitively, this assumption means that knowing whether a certain spam message contains the word bitcoin gives you no information about whether that same message contains the word rolex. In math terms, this means that:\n",
    "\n",
    "$$P(X_1=x_1,...,X_n=x_n|S) = P(X_1=x_1|S)x...xP(X_n=x_n|S)$$\n",
    "\n",
    "The only thing left is to decide how to calculate $p(x\\,|\\,C_k)$ and $p(x\\,|\\,\\neg C_k)$. A simple version would be to estimate them as the fraction of spam/ham messages containing the word $x_i$ a problem arises if a word is never in a spam email we would get a 0 for that term so any message containing that word would never be classified as spam. Therefore we need smoothing. In particular, we'll choose a pseudocount k and estimate the probability of seeing the ith word in a spam message as:\n",
    "\n",
    "$$P(X_i|S) = (k + \\text{number of spams with w_i})\\;/\\;(\\text{anzahl Klassen}\\,x\\,k + \\text{number of spams})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text: str) -> Set:\n",
    "    text = text.lower()\n",
    "    all_words = text.split()\n",
    "    return set(all_words)\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool\n",
    "        \n",
    "import math\n",
    "import math\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 1) -> None:\n",
    "        self.k = k # smoothing factor\n",
    "        \n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str,int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str,int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "        \n",
    "    def train(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages +=1\n",
    "                \n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] +=1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] +=1\n",
    "    \n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        \"\"\"returns P(token|spam) and P(token|ham)\"\"\"\n",
    "        \n",
    "        spam_count = self.token_spam_counts[token]\n",
    "        ham_count = self.token_ham_counts[token]\n",
    "        \n",
    "        p_token_spam = (spam_count + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham_count + self.k) / (self.ham_messages + 2 * self.k)\n",
    "        \n",
    "        return p_token_spam, p_token_ham\n",
    "    \n",
    "    def predict(self, text: str) -> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "        \n",
    "        # Iterate through each word in our vocabulary to calculate (P(tokens|spam) and P(tokens|ham))\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "            \n",
    "            # if token is in the message, add the log probability of seeing it\n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "                \n",
    "            # otherwise add the log probability of not seeing it\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "                \n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "messages = [Message(\"spam rules\", is_spam=True),\n",
    "            Message(\"ham rules\", is_spam=False),\n",
    "            Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=1)\n",
    "model.train(messages)\n",
    "model.predict('hello spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO  # So we can treat bytes as a file.\n",
    "import requests         # To download the files, which\n",
    "import tarfile          # are in .tar.bz format.\n",
    "\n",
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "for filename in FILES:\n",
    "    # Use requests to get the file contents at each URL.\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "\n",
    "    # Wrap the in-memory bytes so we can use them as a \"file.\"\n",
    "    fin = BytesIO(content)\n",
    "\n",
    "    # And extract all the files to the specified output dir.\n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import glob, re\n",
    "\n",
    "path = 'spam_data/*/*'\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "\n",
    "    # There are some garbage characters in the emails; the errors='ignore'\n",
    "    # skips them instead of raising an exception.\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break  # done with this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_messages, test_messages = split_data(data, 0.75)\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]\n",
    "\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)\n",
    "\n",
    "pprint.pprint(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(\"spammiest_words\", words[-5:])\n",
    "print(\"hammiest_words\", words[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import notebook as tqdm_notebook\n",
    "\n",
    "class SimpleLinearRegression:\n",
    "    def __init__(self) -> None:\n",
    "        self.beta: float = 1.0\n",
    "        self.alpha: float = 1.0\n",
    "        self.x: Vector = None\n",
    "        self.y: Vector = None\n",
    "    \n",
    "    def predict(self, alpha: float, beta: float, x_i: float) -> float:\n",
    "        return alpha + beta * x_i\n",
    "    \n",
    "    def __error(self, alpha: float, beta: float, x_i: float, y_i: float) -> float:\n",
    "        \"\"\"The error from predicting alpha + beta * x_i when the actual value is y_i\"\"\"\n",
    "        return self.predict(alpha, beta, x_i) - y_i\n",
    "    \n",
    "    def __sum_of_sqerrors(self, alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "        return sum(self.__error(alpha, beta, x_i, y_i) ** 2 for x_i, y_i in zip(x,y))\n",
    "    \n",
    "    def __total_sum_of_squares(self) -> float:\n",
    "        \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "        return sum(v ** 2 for v in de_mean(self.y))\n",
    "\n",
    "    def r_squared(self) -> float:\n",
    "        \"\"\"\n",
    "        the fraction of variation in y captured by the model, which equals\n",
    "        1 - the fraction of variation in y not captured by the model\n",
    "        \"\"\"\n",
    "        return 1.0 - (self.__sum_of_sqerrors(self.alpha, self.beta, self.x, self.y) / self.__total_sum_of_squares())\n",
    "    \n",
    "    def least_squares_fit(self, x: Vector, y: Vector) -> Tuple[float, float]:\n",
    "        \"\"\"Given two vectors x and y, find the least-squares values of alpha and beta\"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.beta = correlation(x,y) * standard_deviation(y) / standard_deviation(x)\n",
    "        self.alpha = mean(y) - self.beta * mean(x)\n",
    "        return self.alpha, self.beta\n",
    "    \n",
    "    def gradient_descent(self, x: Vector, y: Vector, num_epochs: int = 10000, learning_rate: float = 0.00001) -> Tuple[float, float]:\n",
    "        guess = [random.random(), random.random()]\n",
    "        \n",
    "        with tqdm_notebook.trange(num_epochs) as t:\n",
    "            for _ in t:\n",
    "                alpha, beta = guess\n",
    "                \n",
    "                # partial derivative of loss with respect to alpha\n",
    "                grad_a = sum(2 * self.__error(alpha, beta, x_i, y_i) for x_i, y_i in zip(x,y))\n",
    "                \n",
    "                # partial derivative of loss with respect to beta\n",
    "                grad_b = sum(2 * self.__error(alpha, beta, x_i, y_i) * x_i for x_i, y_i, in zip(x,y))\n",
    "                \n",
    "                # compute loss\n",
    "                loss = self.__sum_of_sqerrors(alpha, beta, x, y)\n",
    "                t.set_description(f'loss:{loss:.3f}')\n",
    "                \n",
    "                guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n",
    "                \n",
    "        return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x = [i for i in range(-100, 110, 10)]\n",
    "y = [3 * i - 5 for i in x]\n",
    "\n",
    "# Should find that y = 3x - 5\n",
    "lr = SimpleLinearRegression()\n",
    "lr.least_squares_fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lr.r_squared()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lr.gradient_descent(x,y, num_epochs = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression\n",
    "\n",
    "linear models with multiple independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def predict(x: Vector, beta: Vector) -> float:\n",
    "        \"\"\"assumes that the first element of x is 1\"\"\"\n",
    "        return dot(x, beta)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}